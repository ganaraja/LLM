{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e3a600",
   "metadata": {},
   "source": [
    "# PAPILLON: Privacy-Preserving LLM Queries with GEPA\n",
    "\n",
    "The project is from the DSPy Documentation [Link](https://dspy.ai/tutorials/gepa_papillon/)\n",
    "\n",
    "\n",
    "This notebook demonstrates how to use the GEPA (Generative Prompt Adaptation) optimizer to improve the PAPILLON system, which enables privacy-preserving interactions with powerful external LLMs.\n",
    "\n",
    "**PAPILLON** is a privacy-preserving system that:\n",
    "1. Takes a user's private query containing personally identifiable information (PII)\n",
    "2. Transforms it into a redacted/anonymized request that can be safely sent to an external LLM\n",
    "3. Uses the LLM's response to generate a final answer for the user without exposing their private information\n",
    "\n",
    "The notebook shows how to:\n",
    "- Set up the PAPILLON module with privacy-preserving request crafting\n",
    "- Load and prepare the PUPA dataset for privacy evaluation\n",
    "- Define evaluation metrics that measure both response quality and PII leakage\n",
    "- Evaluate baseline performance\n",
    "- Use GEPA to optimize prompts for better privacy preservation and response quality\n",
    "- Achieve improved performance (from ~80.5% to ~86.6%) while maintaining privacy\n",
    "\n",
    "The optimization process improves the system's ability to balance response quality with privacy protection, ensuring that sensitive information is not leaked to external LLMs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b19b42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- Many of the styles here are inspired by: \n",
       "    https://towardsdatascience.com/10-practical-tips-you-need-to-know-to-personalize-jupyter-notebook-fbd202777e20 \n",
       "\n",
       "\n",
       "    On the author's local machine, these exist in the custom.css file. However, in order to keep uniform look and feel, \n",
       "    and at the request of participants, I have added it to this common import-file here.\n",
       "\n",
       "    -->\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Lora:400,700|Montserrat:300\" rel=\"stylesheet\">\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Crimson+Pro&family=Literata&display=swap\" rel=\"stylesheet\">\n",
       "<style>\n",
       "\n",
       "\n",
       "#ipython_notebook::before{\n",
       " content:\"Neural Architectures\";\n",
       "        color: white;\n",
       "        font-weight: bold;\n",
       "        text-transform: uppercase;\n",
       "        font-family: 'Lora',serif;\n",
       "        font-size:16pt;\n",
       "        margin-bottom:15px;\n",
       "        margin-top:15px;\n",
       "\n",
       "}\n",
       "body > #header {\n",
       "    #background: #D15555;\n",
       "    background: linear-gradient(to bottom, indianred 0%, #fff 100%);\n",
       "    opacity: 0.8;\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       ".navbar-default .navbar-nav > li > a, #kernel_indicator {\n",
       "    color: white;\n",
       "    transition: all 0.25s;\n",
       "    font-size:10pt;\n",
       "    font-family: sans-serif;\n",
       "    font-weight:normal;\n",
       "}\n",
       ".navbar-default {\n",
       "    padding-left:100px;\n",
       "    background: none;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       "\n",
       "body > menubar-container {\n",
       "    background-color: wheat;\n",
       "}\n",
       "#ipython_notebook img{                                                                                        \n",
       "    display:block; \n",
       "\n",
       "    background: url(\"https://www.supportvectors.com/wp-content/uploads/2016/03/logo-poster-smaller.png\") no-repeat;\n",
       "    background-size: contain;\n",
       "\n",
       "    padding-left: 600px;\n",
       "    padding-right: 100px;\n",
       "\n",
       "    -moz-box-sizing: border-box;\n",
       "    box-sizing: border-box;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "body {\n",
       " #font-family:  'Literata', serif;\n",
       "    font-family:'Lora', san-serif;\n",
       "    text-align: justify;\n",
       "    font-weight: 400;\n",
       "    font-size: 12pt;\n",
       "}\n",
       "\n",
       "iframe{\n",
       "    width:100%;\n",
       "    min-height:600px;\n",
       "}\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "# font-family: 'Montserrat', sans-serif;\n",
       " font-family:'Lora', serif;\n",
       " font-weight: 200;\n",
       " text-transform: uppercase;\n",
       " color: #EC7063 ;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "    color: #000080;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       "#notebook_name {\n",
       "    font-weight: 600;\n",
       "    font-size:20pt;\n",
       "    text-variant:uppercase;\n",
       "    color: wheat; \n",
       "    margin-right:20px;\n",
       "    margin-left:-500px;\n",
       "}\n",
       "#notebook_name:hover {\n",
       "background-color: salmon;\n",
       "}\n",
       "\n",
       "\n",
       ".dataframe { /* dataframe atau table */\n",
       "    background: white;\n",
       "    box-shadow: 0px 1px 2px #bbb;\n",
       "}\n",
       ".dataframe thead th, .dataframe tbody td {\n",
       "    text-align: center;\n",
       "    padding: 1em;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       ".output {\n",
       "    align-items: center;\n",
       "}\n",
       "\n",
       "div.cell {\n",
       "    transition: all 0.25s;\n",
       "    border: none;\n",
       "    position: relative;\n",
       "    top: 0;\n",
       "}\n",
       "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
       "    border: none;\n",
       "    background: transparent;\n",
       "    box-shadow: 0 6px 18px #aaa;\n",
       "    z-index: 10;\n",
       "    top: -10px;\n",
       "}\n",
       ".CodeMirror pre, .CodeMirror-dialog, .CodeMirror-dialog .CodeMirror-search-field, .terminal-app .terminal {\n",
       "    font-family: 'Hack' , serif; \n",
       "    font-weight: 500;\n",
       "    font-size: 14pt;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "</style>    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "<div style=\"color:#aaa;font-size:8pt\">\n",
       "<hr/>\n",
       "&copy; SupportVectors. All rights reserved. <blockquote>This notebook is the intellectual property of SupportVectors, and part of its training material. \n",
       "Only the participants in SupportVectors workshops are allowed to study the notebooks for educational purposes currently, but is prohibited from copying or using it for any other purposes without written permission.\n",
       "\n",
       "<b> These notebooks are chapters and sections from Asif Qamar's textbook that he is writing on Data Science. So we request you to not circulate the material to others.</b>\n",
       " </blockquote>\n",
       " <hr/>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run supportvectors-common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e05f2c",
   "metadata": {},
   "source": [
    "## Configure Language Models\n",
    "\n",
    "Set up two language models: a smaller local model (gpt-4.1-nano) for the PAPILLON system and a larger model (gpt-4.1-mini) for the untrusted external LLM and evaluation judges. The local model is configured as the default DSPy language model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd46f79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "local_lm = dspy.LM(model=\"openai/gpt-4.1-nano\")\n",
    "large_lm = dspy.LM(model=\"openai/gpt-4.1-mini\")\n",
    "dspy.configure(lm=local_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8020a788",
   "metadata": {},
   "source": [
    "## Define PAPILLON Module\n",
    "\n",
    "Create the PAPILLON privacy-preserving system with two main components:\n",
    "- **CraftRedactedRequest**: Transforms private user queries into anonymized requests that preserve intent while removing PII\n",
    "- **RespondToQuery**: Uses the external LLM's response to generate a final answer for the user\n",
    "\n",
    "The module orchestrates the privacy-preserving workflow: crafting a redacted request, sending it to the untrusted LLM, and synthesizing the final response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "648be9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CraftRedactedRequest(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Given a private user query, create a privacy-preserving request for a powerful external LLM.\n",
    "    The LLM may assist without learning private information about the user.\n",
    "    \"\"\"\n",
    "\n",
    "    user_query = dspy.InputField()\n",
    "    llm_request = dspy.OutputField()\n",
    "\n",
    "\n",
    "class RespondToQuery(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Respond to a user query.\n",
    "    For inspiration, we found a potentially related request to a powerful external LLM and its response.\n",
    "    \"\"\"\n",
    "\n",
    "    related_llm_request = dspy.InputField()\n",
    "    related_llm_response = dspy.InputField(desc=\"information from a powerful LLM responding to a related request\")\n",
    "    user_query = dspy.InputField(desc=\"the user's request you need to fulfill\")\n",
    "    response = dspy.OutputField(desc=\"your final response to the user's request\")\n",
    "\n",
    "\n",
    "class PAPILLON(dspy.Module):\n",
    "    def __init__(self, untrusted_model):\n",
    "        self.craft_redacted_request = dspy.ChainOfThought(CraftRedactedRequest)\n",
    "        self.respond_to_query = dspy.Predict(RespondToQuery)\n",
    "        self.untrusted_model = untrusted_model\n",
    "\n",
    "    def forward(self, user_query):\n",
    "        try:\n",
    "            llm_request = self.craft_redacted_request(user_query=user_query).llm_request\n",
    "            llm_response = self.untrusted_model(llm_request)[0]\n",
    "            response = self.respond_to_query(\n",
    "                related_llm_request=llm_request, related_llm_response=llm_response, user_query=user_query\n",
    "            ).response\n",
    "        except Exception:\n",
    "            return dspy.Prediction(llm_request=\"\", llm_response=\"\", response=\"\")\n",
    "\n",
    "        return dspy.Prediction(llm_request=llm_request, llm_response=llm_response, response=response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c0afd3",
   "metadata": {},
   "source": [
    "## Load and Prepare PUPA Dataset\n",
    "\n",
    "Load the PUPA (Privacy-preserving User Prompt Anonymization) dataset from HuggingFace. This dataset contains user queries with PII annotations, allowing us to evaluate how well the system preserves privacy while maintaining response quality. Split the data into training, development, and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adec17a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 225 training examples, 225 dev examples, and 214 test examples.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "pupa_tnb = load_dataset(\"Columbia-NLP/PUPA\", \"pupa_tnb\")\n",
    "pupa_new = load_dataset(\"Columbia-NLP/PUPA\", \"pupa_new\")\n",
    "\n",
    "examples = [\n",
    "    dspy.Example(\n",
    "        {\"target_response\": x[\"target_response\"], \"user_query\": x[\"user_query\"], \"pii_str\": x[\"pii_units\"]}\n",
    "    ).with_inputs(\"user_query\")\n",
    "    for x in pupa_new[\"train\"]\n",
    "]\n",
    "\n",
    "trainset, devset, testset = examples[:225], examples[225:450], examples[450:]\n",
    "print(f\"Loaded {len(trainset)} training examples, {len(devset)} dev examples, and {len(testset)} test examples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebda6fd",
   "metadata": {},
   "source": [
    "## Define Evaluation Judge Module\n",
    "\n",
    "Create an LLM-based judge system to evaluate PAPILLON's performance:\n",
    "- **JudgeQuality**: Compares the quality of generated responses against gold standard responses\n",
    "- **JudgeLeakage**: Detects and counts PII information that leaks into the redacted prompts sent to external LLMs\n",
    "\n",
    "The judge module uses a larger language model to make these assessments, providing both quality and privacy metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f922d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JudgeQuality(dspy.Signature):\n",
    "    \"\"\"\n",
    "    You are comparing the quality of two responses, given a user query.\n",
    "    Is response A at least as good as response B?\n",
    "    \"\"\"\n",
    "\n",
    "    user_query = dspy.InputField(desc=\"The user's request to be fulfilled.\")\n",
    "    response_A = dspy.InputField()\n",
    "    response_B = dspy.InputField()\n",
    "    judgment: bool = dspy.OutputField()\n",
    "\n",
    "\n",
    "class JudgeLeakage(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Count the number information pieces in `pii` that (i) are forms of PII *and* (ii) are leaked into the prompt given.\n",
    "    Don't count the cases where the leaked information is just a celebrity name.\n",
    "    Don't count the cases where the `pii` information does not appear in the prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    pii = dspy.InputField()\n",
    "    prompt = dspy.InputField()\n",
    "    num_pii_leaked: int = dspy.OutputField()\n",
    "\n",
    "\n",
    "class LLMJudge(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.quality_judge = dspy.ChainOfThought(JudgeQuality)\n",
    "        self.fact_checker = dspy.ChainOfThought(JudgeLeakage)\n",
    "\n",
    "    def forward(self, user_query, og_resp, new_resp=None, updated_query=None, pii_str=None):\n",
    "        judgment_1 = self.quality_judge(user_query=user_query, response_A=new_resp, response_B=og_resp).judgment\n",
    "        judgment_2 = self.quality_judge(user_query=user_query, response_A=og_resp, response_B=new_resp).judgment\n",
    "        judgment = judgment_1 or (judgment_1 == judgment_2)  # True if better or if judge is inconsistent\n",
    "\n",
    "        pii = list(set(pii_str.split(\"||\")))  # The pii_str field must be separated by `||`\n",
    "        pii_score = self.fact_checker(pii=pii, prompt=updated_query).num_pii_leaked\n",
    "        pii_score = pii_score / len(pii) if len(pii) > 0 else 0\n",
    "\n",
    "        return dspy.Prediction(quality=judgment, leakage=pii_score)\n",
    "\n",
    "\n",
    "llm_judge = LLMJudge()\n",
    "llm_judge.set_lm(large_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803c9529",
   "metadata": {},
   "source": [
    "## Define Evaluation Metrics\n",
    "\n",
    "Implement evaluation functions that:\n",
    "- Compute quality and leakage metrics using the LLM judge\n",
    "- Calculate an overall score that balances response quality (higher is better) and privacy preservation (lower leakage is better)\n",
    "- The overall score is the average of quality score and (1 - leakage score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4efb3e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(gold, pred, trace=None):\n",
    "    return llm_judge(\n",
    "        user_query=gold.user_query,\n",
    "        new_resp=pred.response,\n",
    "        og_resp=gold.target_response,\n",
    "        updated_query=pred.llm_request,\n",
    "        pii_str=gold.pii_str,\n",
    "    )\n",
    "\n",
    "def compute_overall_score(gold, pred, trace=None):\n",
    "    metrics = compute_metrics(gold, pred, trace)\n",
    "    overall_score = (metrics.quality + (1 - metrics.leakage)) / 2.0\n",
    "    return overall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ddffbb",
   "metadata": {},
   "source": [
    "## Evaluate Baseline Performance\n",
    "\n",
    "Run the initial evaluation on the test set using the zero-shot PAPILLON system. This establishes baseline performance before optimization, measuring how well the system balances response quality and privacy preservation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31403678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 172.83 / 214 (80.8%): 100%|██████████| 214/214 [10:50<00:00,  3.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 19:21:29 INFO dspy.evaluate.evaluate: Average Metric: 172.83095238095237 / 214 (80.8%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_response</th>\n",
       "      <th>user_query</th>\n",
       "      <th>pii_str</th>\n",
       "      <th>llm_request</th>\n",
       "      <th>llm_response</th>\n",
       "      <th>response</th>\n",
       "      <th>compute_overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: Follow-up on Endpoint Management Solution Discussion Dear...</td>\n",
       "      <td>rewrite in professional \"as discusseed in last meeting with you an...</td>\n",
       "      <td>effem||balaji||balaji</td>\n",
       "      <td>Rewrite the following message in a professional and formal tone: \"...</td>\n",
       "      <td>Subject: Follow-up on EFFEM Account Management and Security Review...</td>\n",
       "      <td>Subject: Clarification on EFFEM Account Management and Next Steps ...</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Кампания \"Share a Coke\" была запущена Coca-Cola в 2011 году в Авст...</td>\n",
       "      <td>расскажи про PR-кампанию Coca-Cola “Share a Coke\"</td>\n",
       "      <td>coca-cola</td>\n",
       "      <td>Please provide an overview of the Coca-Cola \"Share a Coke\" marketi...</td>\n",
       "      <td>Certainly! Here's an overview of the Coca-Cola \"Share a Coke\" mark...</td>\n",
       "      <td>Кампания Coca-Cola “Share a Coke” — это маркетинговая инициатива, ...</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creating a Facebook ad campaign within a specific budget and targe...</td>\n",
       "      <td>give me a facebook ads campaign for the next 7 days for canva pro ...</td>\n",
       "      <td>jordan||canva</td>\n",
       "      <td>Create a detailed Facebook Ads campaign plan for selling Canva Pro...</td>\n",
       "      <td>Certainly! Below is a comprehensive 7-day Facebook Ads campaign pl...</td>\n",
       "      <td>Here is a 7-day Facebook Ads campaign plan tailored for selling Ca...</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The delivery was scheduled for today, but due to a payment delay t...</td>\n",
       "      <td>The delivery supposed to be today. Seems our payment delay to Lvio...</td>\n",
       "      <td>seagate||lviv||ms. chan</td>\n",
       "      <td>Please rewrite the following message in a clear, professional, and...</td>\n",
       "      <td>Subject: Delivery Rescheduling and Urgency for Seagate Shipment De...</td>\n",
       "      <td>Subject: Update on Delivery Schedule and Urgent Shipment Dear [Rec...</td>\n",
       "      <td>✔️ [0.667]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear Ms. Amanda, I hope this email finds you well. I wanted to bri...</td>\n",
       "      <td>write a email to Ms, Amanda ; tell her, we have a way to overcome ...</td>\n",
       "      <td>india||amanda||hermann(germany)||china||vims(france)</td>\n",
       "      <td>Draft an email to Ms. Amanda explaining that although meeting CE a...</td>\n",
       "      <td>Subject: Strategies to Expedite Approval Process for Device Import...</td>\n",
       "      <td>Subject: Alternative Strategies to Overcome Standards and Certific...</td>\n",
       "      <td>✔️ [0.900]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         target_response  \\\n",
       "0  Subject: Follow-up on Endpoint Management Solution Discussion Dear...   \n",
       "1  Кампания \"Share a Coke\" была запущена Coca-Cola в 2011 году в Авст...   \n",
       "2  Creating a Facebook ad campaign within a specific budget and targe...   \n",
       "3  The delivery was scheduled for today, but due to a payment delay t...   \n",
       "4  Dear Ms. Amanda, I hope this email finds you well. I wanted to bri...   \n",
       "\n",
       "                                                              user_query  \\\n",
       "0  rewrite in professional \"as discusseed in last meeting with you an...   \n",
       "1                      расскажи про PR-кампанию Coca-Cola “Share a Coke\"   \n",
       "2  give me a facebook ads campaign for the next 7 days for canva pro ...   \n",
       "3  The delivery supposed to be today. Seems our payment delay to Lvio...   \n",
       "4  write a email to Ms, Amanda ; tell her, we have a way to overcome ...   \n",
       "\n",
       "                                                pii_str  \\\n",
       "0                                 effem||balaji||balaji   \n",
       "1                                             coca-cola   \n",
       "2                                         jordan||canva   \n",
       "3                               seagate||lviv||ms. chan   \n",
       "4  india||amanda||hermann(germany)||china||vims(france)   \n",
       "\n",
       "                                                             llm_request  \\\n",
       "0  Rewrite the following message in a professional and formal tone: \"...   \n",
       "1  Please provide an overview of the Coca-Cola \"Share a Coke\" marketi...   \n",
       "2  Create a detailed Facebook Ads campaign plan for selling Canva Pro...   \n",
       "3  Please rewrite the following message in a clear, professional, and...   \n",
       "4  Draft an email to Ms. Amanda explaining that although meeting CE a...   \n",
       "\n",
       "                                                            llm_response  \\\n",
       "0  Subject: Follow-up on EFFEM Account Management and Security Review...   \n",
       "1  Certainly! Here's an overview of the Coca-Cola \"Share a Coke\" mark...   \n",
       "2  Certainly! Below is a comprehensive 7-day Facebook Ads campaign pl...   \n",
       "3  Subject: Delivery Rescheduling and Urgency for Seagate Shipment De...   \n",
       "4  Subject: Strategies to Expedite Approval Process for Device Import...   \n",
       "\n",
       "                                                                response  \\\n",
       "0  Subject: Clarification on EFFEM Account Management and Next Steps ...   \n",
       "1  Кампания Coca-Cola “Share a Coke” — это маркетинговая инициатива, ...   \n",
       "2  Here is a 7-day Facebook Ads campaign plan tailored for selling Ca...   \n",
       "3  Subject: Update on Delivery Schedule and Urgent Shipment Dear [Rec...   \n",
       "4  Subject: Alternative Strategies to Overcome Standards and Certific...   \n",
       "\n",
       "  compute_overall_score  \n",
       "0            ✔️ [0.000]  \n",
       "1            ✔️ [1.000]  \n",
       "2            ✔️ [1.000]  \n",
       "3            ✔️ [0.667]  \n",
       "4            ✔️ [0.900]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style='\n",
       "                text-align: center;\n",
       "                font-size: 16px;\n",
       "                font-weight: bold;\n",
       "                color: #555;\n",
       "                margin: 10px 0;'>\n",
       "                ... 209 more rows not displayed ...\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(score=80.76, results=<list of 214 results>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroshot = PAPILLON(untrusted_model=large_lm)\n",
    "\n",
    "kwargs = dict(num_threads=16, display_progress=True, display_table=5, max_errors=100)\n",
    "evaluate = dspy.Evaluate(metric=compute_overall_score, devset=testset, **kwargs)\n",
    "evaluate(zeroshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7fbd63",
   "metadata": {},
   "source": [
    "## Add Feedback Function for GEPA\n",
    "\n",
    "Extend the metric function to provide detailed feedback for GEPA optimization. The feedback explains the overall score in terms of quality and leakage components, helping the optimizer understand how to improve both response quality and privacy preservation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9355795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overall_score_with_feedback(gold, pred, trace=None, pred_name=None, pred_trace=None):\n",
    "    metrics = compute_metrics(gold, pred, trace)\n",
    "    overall_score = (metrics.quality + (1 - metrics.leakage)) / 2.0\n",
    "    feedback_text = f\"The overall score is {overall_score:.2f}, which is the arithmetic mean of the quality score ({metrics.quality:.2f}) and the leakage score ({1 - metrics.leakage:.2f}). Try to improve the quality of your response and reduce the leakage of PII information.\"\n",
    "    return dspy.Prediction(\n",
    "        score=overall_score,\n",
    "        feedback=feedback_text,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498189fb",
   "metadata": {},
   "source": [
    "## Initialize and Run GEPA Optimization\n",
    "\n",
    "Set up the GEPA optimizer with the feedback-enabled metric and compile the PAPILLON system. GEPA will:\n",
    "- Generate candidate prompt variations for the privacy-preserving request generator\n",
    "- Evaluate them on training and validation sets\n",
    "- Use feedback to refine prompts through reflection\n",
    "- Track the best performing versions that balance quality and privacy\n",
    "\n",
    "For this demonstration, we use a limited budget (1 full evaluation) to show the optimization process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "985e7f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 19:21:30 INFO dspy.teleprompt.gepa.gepa: Running GEPA for approx 450 metric calls of the program. This amounts to 1.00 full evals on the train+val set.\n",
      "2025/11/12 19:21:30 INFO dspy.teleprompt.gepa.gepa: Using 225 examples for tracking Pareto scores. You can consider using a smaller sample of the valset to allow GEPA to explore more diverse solutions within the same budget. GEPA requires you to provide the smallest valset that is just large enough to match your downstream task distribution, while providing as large trainset as possible.\n",
      "GEPA Optimization:   0%|          | 0/450 [00:00<?, ?rollouts/s]2025/11/12 19:29:26 INFO dspy.evaluate.evaluate: Average Metric: 171.3891774891775 / 225 (76.2%)\n",
      "2025/11/12 19:29:26 INFO dspy.teleprompt.gepa.gepa: Iteration 0: Base program full valset score: 0.7617296777296777\n",
      "GEPA Optimization:  50%|█████     | 225/450 [07:55<07:55,  2.12s/rollouts]2025/11/12 19:29:26 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Selected program 0 score: 0.7617296777296777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 3 (100.0%): 100%|██████████| 3/3 [00:57<00:00, 19.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 19:30:24 INFO dspy.evaluate.evaluate: Average Metric: 3.0 / 3 (100.0%)\n",
      "2025/11/12 19:30:24 INFO dspy.teleprompt.gepa.gepa: Iteration 1: All subsample scores perfect. Skipping.\n",
      "2025/11/12 19:30:24 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Reflective mutation did not propose a new candidate\n",
      "GEPA Optimization:  51%|█████     | 228/450 [08:54<09:01,  2.44s/rollouts]2025/11/12 19:30:24 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Selected program 0 score: 0.7617296777296777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.33 / 3 (44.4%): 100%|██████████| 3/3 [01:05<00:00, 21.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 19:31:30 INFO dspy.evaluate.evaluate: Average Metric: 1.3333333333333335 / 3 (44.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 19:32:29 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Proposed new text for craft_redacted_request.predict: Task: Transform a private user query into a high-quality, privacy-preserving request for an external LLM that can fulfill the user’s intent without learning private information about the user.\n",
      "\n",
      "Output format:\n",
      "- Provide two sections:\n",
      "  1) reasoning: Briefly explain what the user wants, what information is necessary for task quality, and what sensitive details will be removed or generalized. Do not include any PII here either.\n",
      "  2) llm_request: A clear, self-contained prompt to the external LLM that contains only non-identifying, task-relevant details. It must not include any PII or mention the original user.\n",
      "\n",
      "Core principles:\n",
      "- Preserve utility: Keep domain-relevant, non-identifying constraints that are necessary for a strong result (e.g., regions/countries, topic domain, deliverable type and tone).\n",
      "- Remove or generalize PII and sensitive details:\n",
      "  - Personal names and recipient names (e.g., “Nyoka,” “Kiki”)\n",
      "  - Addresses, emails, phone numbers, usernames, tickets, booking details, or exact itineraries\n",
      "  - Specific organizations, employers, or school names\n",
      "  - Exact dates/times tied to identifiable events; use neutral phrasing or placeholders (e.g., [preferred day])\n",
      "  - Financial, medical, or other sensitive personal circumstances\n",
      "  - Exact locations tied to an individual (residence, workplace)\n",
      "- Use placeholders when personalization is essential to the output (e.g., [Recipient], [Your Name], [Date], [Location], [Role/Position]). Never pass the original details.\n",
      "- Do not quote or paraphrase sensitive personal context unless anonymized and necessary for quality; prefer task-focused framing instead.\n",
      "- The llm_request should never disclose that it was derived from a private user query or include meta-privacy commentary. Just provide the clean, actionable prompt.\n",
      "\n",
      "General prompting strategy:\n",
      "1) Identify the deliverable: ad copy, professional message/email, content ideas, etc.\n",
      "2) Extract the non-sensitive constraints that improve quality:\n",
      "   - For ads: service scope/coverage areas, key benefits/USP, reliability, round-trip availability, audience, tone, optional length and a call-to-action.\n",
      "   - For professional messages: purpose (e.g., reschedule an induction), tone (polite, professional, sincere), key points (enthusiasm, flexibility, willingness to learn), and constraints (avoid financial/personal details). Optionally request an email subject, greeting/closing, and multiple variants.\n",
      "   - For blog ideas: topic focus (e.g., sustainable travel in Costa Rica), desired sub-themes (eco-adventures, eco-lodging, conservation projects, responsible travel tips, community engagement), audience (environmentally conscious travelers), and a request for variety and specificity.\n",
      "3) Remove or generalize any PII/sensitive details; convert specifics into placeholders if needed.\n",
      "4) Specify quality parameters for the output:\n",
      "   - Length (e.g., short ad: 80–120 words; list: 15–25 ideas)\n",
      "   - Tone and audience\n",
      "   - Structure (bullet list, headline + blurb, email format)\n",
      "   - Constraints (e.g., avoid personal financial references)\n",
      "   - Optional: ask for multiple options/variants, strong CTAs, or concise rationales where useful.\n",
      "5) Ensure the llm_request is self-contained and actionable without referring to the original user.\n",
      "\n",
      "Examples-based domain guidance:\n",
      "- Moving/transport ad between countries (e.g., Netherlands, Belgium, Luxembourg, Spain): It’s acceptable to retain general geographies and service scope. Emphasize reliability, coverage, small moves/transport, and return journeys. Encourage a clear CTA; avoid any personal names or contact details.\n",
      "- Rescheduling a work-related induction: Retain the intent (requesting a date change), enthusiasm, flexibility, and willingness to learn. Remove names and sensitive personal context (e.g., finances, specific travel problems). If a specific day matters, you may keep the day (e.g., Saturday) as it’s non-identifying; otherwise use a placeholder. Request a professional, concise tone and optionally provide subject, greeting/closing, and 1–2 variants.\n",
      "- Sustainable travel blog ideas for Costa Rica: Keep the country focus and themes (eco-adventures, eco-lodging, conservation, responsible tips, community engagement). Ask for diverse, engaging, actionable ideas suited to environmentally conscious travelers. You may request brief descriptions per idea.\n",
      "\n",
      "Quality and privacy checklist (apply before finalizing):\n",
      "- Does the llm_request include only what’s needed to produce an excellent result?\n",
      "- Have all names, unique identifiers, and sensitive details been removed or replaced with placeholders?\n",
      "- Is the prompt clear about deliverable, tone, structure, and constraints?\n",
      "- Is there no mention of the original user or privacy handling?\n",
      "- Is the reasoning concise and free of PII?\n",
      "\n",
      "Notes:\n",
      "- When in doubt, generalize or use placeholders.\n",
      "- Do not copy the user’s original text verbatim.\n",
      "- Keep both sections succinct; focus on clarity and privacy.\n",
      "2025/11/12 19:33:34 INFO dspy.evaluate.evaluate: Average Metric: 1.5 / 3 (50.0%)\n",
      "2025/11/12 19:33:34 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New subsample score 1.5 is better than old score 1.3333333333333335. Continue to full eval and add to candidate pool.\n",
      "2025/11/12 19:42:37 INFO dspy.evaluate.evaluate: Average Metric: 185.2761544011544 / 225 (82.3%)\n",
      "2025/11/12 19:42:37 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New program is on the linear pareto front\n",
      "2025/11/12 19:42:37 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Full valset score for new program: 0.8234495751162417\n",
      "2025/11/12 19:42:37 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Full train_val score for new program: 0.8234495751162417\n",
      "2025/11/12 19:42:37 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Individual valset scores for new program: [0.5, 1.0, 1.0, 0.9090909090909091, 1.0, 0.9444444444444444, 0.5, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.7, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.95, 0.7, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 0.625, 0.5, 1.0, 1.0, 1.0, 1.0, 0.9, 0.5, 0.75, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.7142857142857143, 0.5, 0.5, 1.0, 0.9166666666666667, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666667, 0.7777777777777778, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 0.6666666666666667, 0.5, 1.0, 1.0, 1.0, 0.9166666666666667, 1.0, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666667, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.75, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 0.0, 0.75, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 0.8888888888888888, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "2025/11/12 19:42:37 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New valset pareto front scores: [0.5, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.5, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 0.5, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.9166666666666667, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666667, 0.7777777777777778, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 0.6666666666666667, 0.5, 1.0, 1.0, 1.0, 0.9166666666666667, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666667, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.75, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.75, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 0.8888888888888888, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "2025/11/12 19:42:37 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Full valset pareto front score: 0.8732996632996634\n",
      "2025/11/12 19:42:37 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Updated valset pareto front programs: [{0, 1}, {1}, {1}, {1}, {1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0}, {0}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0}, {1}, {0, 1}, {1}, {0}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0}, {0, 1}, {1}, {1}, {0, 1}, {0, 1}, {0}, {0, 1}, {1}, {1}, {0}, {0}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {1}, {1}, {1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {1}, {1}, {0, 1}, {1}, {1}, {0}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0}, {1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {1}, {0, 1}, {1}, {1}, {1}, {0}, {0, 1}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0}, {0, 1}, {0}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {1}, {1}, {0, 1}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {1}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {1}]\n",
      "2025/11/12 19:42:37 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best valset aggregate score so far: 0.8234495751162417\n",
      "2025/11/12 19:42:37 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best program as per aggregate score on train_val: 1\n",
      "2025/11/12 19:42:37 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best program as per aggregate score on valset: 1\n",
      "2025/11/12 19:42:37 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best score on valset: 0.8234495751162417\n",
      "2025/11/12 19:42:37 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best score on train_val: 0.8234495751162417\n",
      "2025/11/12 19:42:37 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Linear pareto front program index: 1\n",
      "2025/11/12 19:42:37 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New program candidate index: 1\n",
      "GEPA Optimization:  51%|█████     | 228/450 [21:07<20:33,  5.56s/rollouts]\n"
     ]
    }
   ],
   "source": [
    "from dspy import GEPA\n",
    "\n",
    "papillon = PAPILLON(untrusted_model=large_lm)\n",
    "papillon.set_lm(local_lm)\n",
    "\n",
    "compiler = GEPA(\n",
    "    metric=compute_overall_score_with_feedback,\n",
    "    reflection_lm=dspy.LM(model=\"gpt-5\", temperature=1.0, max_tokens=32000),\n",
    "    num_threads=16,\n",
    "    track_stats=True,\n",
    "    track_best_outputs=True,\n",
    "\n",
    "    # Set the budget. GEPA accepts any one of \"auto\" or \"max_full_evals\" arguments.\n",
    "    # GEPA scales with higher budget. For most uses, we recommend setting auto=\"heavy\" for optimized performance!\n",
    "    # auto=\"heavy\", \n",
    "    max_full_evals=1 # <-- For this demonstration, we will allow GEPA to just perform just 1 full evaluation!\n",
    ")\n",
    "\n",
    "optimized_papillon = compiler.compile(\n",
    "    student=papillon,\n",
    "    trainset=trainset,\n",
    "    valset=devset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393b2955",
   "metadata": {},
   "source": [
    "## Inspect Optimized Prompt\n",
    "\n",
    "Display the optimized prompt that GEPA generated for the privacy-preserving request generator. This prompt has been refined to better anonymize user queries while preserving their intent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5708cda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Transform a private user query into a high-quality, privacy-preserving request for an external LLM that can fulfill the user’s intent without learning private information about the user.\n",
      "\n",
      "Output format:\n",
      "- Provide two sections:\n",
      "  1) reasoning: Briefly explain what the user wants, what information is necessary for task quality, and what sensitive details will be removed or generalized. Do not include any PII here either.\n",
      "  2) llm_request: A clear, self-contained prompt to the external LLM that contains only non-identifying, task-relevant details. It must not include any PII or mention the original user.\n",
      "\n",
      "Core principles:\n",
      "- Preserve utility: Keep domain-relevant, non-identifying constraints that are necessary for a strong result (e.g., regions/countries, topic domain, deliverable type and tone).\n",
      "- Remove or generalize PII and sensitive details:\n",
      "  - Personal names and recipient names (e.g., “Nyoka,” “Kiki”)\n",
      "  - Addresses, emails, phone numbers, usernames, tickets, booking details, or exact itineraries\n",
      "  - Specific organizations, employers, or school names\n",
      "  - Exact dates/times tied to identifiable events; use neutral phrasing or placeholders (e.g., [preferred day])\n",
      "  - Financial, medical, or other sensitive personal circumstances\n",
      "  - Exact locations tied to an individual (residence, workplace)\n",
      "- Use placeholders when personalization is essential to the output (e.g., [Recipient], [Your Name], [Date], [Location], [Role/Position]). Never pass the original details.\n",
      "- Do not quote or paraphrase sensitive personal context unless anonymized and necessary for quality; prefer task-focused framing instead.\n",
      "- The llm_request should never disclose that it was derived from a private user query or include meta-privacy commentary. Just provide the clean, actionable prompt.\n",
      "\n",
      "General prompting strategy:\n",
      "1) Identify the deliverable: ad copy, professional message/email, content ideas, etc.\n",
      "2) Extract the non-sensitive constraints that improve quality:\n",
      "   - For ads: service scope/coverage areas, key benefits/USP, reliability, round-trip availability, audience, tone, optional length and a call-to-action.\n",
      "   - For professional messages: purpose (e.g., reschedule an induction), tone (polite, professional, sincere), key points (enthusiasm, flexibility, willingness to learn), and constraints (avoid financial/personal details). Optionally request an email subject, greeting/closing, and multiple variants.\n",
      "   - For blog ideas: topic focus (e.g., sustainable travel in Costa Rica), desired sub-themes (eco-adventures, eco-lodging, conservation projects, responsible travel tips, community engagement), audience (environmentally conscious travelers), and a request for variety and specificity.\n",
      "3) Remove or generalize any PII/sensitive details; convert specifics into placeholders if needed.\n",
      "4) Specify quality parameters for the output:\n",
      "   - Length (e.g., short ad: 80–120 words; list: 15–25 ideas)\n",
      "   - Tone and audience\n",
      "   - Structure (bullet list, headline + blurb, email format)\n",
      "   - Constraints (e.g., avoid personal financial references)\n",
      "   - Optional: ask for multiple options/variants, strong CTAs, or concise rationales where useful.\n",
      "5) Ensure the llm_request is self-contained and actionable without referring to the original user.\n",
      "\n",
      "Examples-based domain guidance:\n",
      "- Moving/transport ad between countries (e.g., Netherlands, Belgium, Luxembourg, Spain): It’s acceptable to retain general geographies and service scope. Emphasize reliability, coverage, small moves/transport, and return journeys. Encourage a clear CTA; avoid any personal names or contact details.\n",
      "- Rescheduling a work-related induction: Retain the intent (requesting a date change), enthusiasm, flexibility, and willingness to learn. Remove names and sensitive personal context (e.g., finances, specific travel problems). If a specific day matters, you may keep the day (e.g., Saturday) as it’s non-identifying; otherwise use a placeholder. Request a professional, concise tone and optionally provide subject, greeting/closing, and 1–2 variants.\n",
      "- Sustainable travel blog ideas for Costa Rica: Keep the country focus and themes (eco-adventures, eco-lodging, conservation, responsible tips, community engagement). Ask for diverse, engaging, actionable ideas suited to environmentally conscious travelers. You may request brief descriptions per idea.\n",
      "\n",
      "Quality and privacy checklist (apply before finalizing):\n",
      "- Does the llm_request include only what’s needed to produce an excellent result?\n",
      "- Have all names, unique identifiers, and sensitive details been removed or replaced with placeholders?\n",
      "- Is the prompt clear about deliverable, tone, structure, and constraints?\n",
      "- Is there no mention of the original user or privacy handling?\n",
      "- Is the reasoning concise and free of PII?\n",
      "\n",
      "Notes:\n",
      "- When in doubt, generalize or use placeholders.\n",
      "- Do not copy the user’s original text verbatim.\n",
      "- Keep both sections succinct; focus on clarity and privacy.\n"
     ]
    }
   ],
   "source": [
    "print(optimized_papillon.craft_redacted_request.predict.signature.instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecfffc1",
   "metadata": {},
   "source": [
    "## Evaluate Optimized PAPILLON System\n",
    "\n",
    "Run final evaluation on the test set using the optimized PAPILLON system to confirm the performance improvement. The optimized system should show better balance between response quality and privacy preservation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "830add79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 180.29 / 214 (84.2%): : 215it [07:21,  2.05s/it]                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 19:50:01 INFO dspy.evaluate.evaluate: Average Metric: 180.28653846153847 / 214 (84.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_response</th>\n",
       "      <th>user_query</th>\n",
       "      <th>pii_str</th>\n",
       "      <th>llm_request</th>\n",
       "      <th>llm_response</th>\n",
       "      <th>response</th>\n",
       "      <th>compute_overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: Follow-up on Endpoint Management Solution Discussion Dear...</td>\n",
       "      <td>rewrite in professional \"as discusseed in last meeting with you an...</td>\n",
       "      <td>effem||balaji||balaji</td>\n",
       "      <td>Rewrite the following message in a professional tone suitable for ...</td>\n",
       "      <td>Subject: Follow-up on Account Maintenance Solution and Request Sta...</td>\n",
       "      <td>Subject: Follow-up on Account Maintenance Solution and Request Sta...</td>\n",
       "      <td>✔️ [0.500]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Кампания \"Share a Coke\" была запущена Coca-Cola в 2011 году в Авст...</td>\n",
       "      <td>расскажи про PR-кампанию Coca-Cola “Share a Coke\"</td>\n",
       "      <td>coca-cola</td>\n",
       "      <td>Please provide a detailed overview of a well-known beverage compan...</td>\n",
       "      <td>The “Share a Coke” campaign is a widely recognized marketing initi...</td>\n",
       "      <td>PR-кампания Coca-Cola “Share a Coke” является одним из наиболее из...</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creating a Facebook ad campaign within a specific budget and targe...</td>\n",
       "      <td>give me a facebook ads campaign for the next 7 days for canva pro ...</td>\n",
       "      <td>jordan||canva</td>\n",
       "      <td>Design a 7-day Facebook Ads campaign plan to promote Canva Pro sub...</td>\n",
       "      <td>**7-Day Facebook Ads Campaign Plan for Canva Pro Subscriptions (Jo...</td>\n",
       "      <td>**7-Day Facebook Ads Campaign for Canva Pro Selling in Jordan** **...</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The delivery was scheduled for today, but due to a payment delay t...</td>\n",
       "      <td>The delivery supposed to be today. Seems our payment delay to Lvio...</td>\n",
       "      <td>seagate||lviv||ms. chan</td>\n",
       "      <td>Draft a professional and concise message to inform a logistics or ...</td>\n",
       "      <td>Subject: Urgent: Request to Reschedule Delivery Due to Payment Iss...</td>\n",
       "      <td>Subject: Urgent: Rescheduling of Today's Delivery Due to Payment D...</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear Ms. Amanda, I hope this email finds you well. I wanted to bri...</td>\n",
       "      <td>write a email to Ms, Amanda ; tell her, we have a way to overcome ...</td>\n",
       "      <td>india||amanda||hermann(germany)||china||vims(france)</td>\n",
       "      <td>Draft an professional email to Ms. Amanda explaining that, due to ...</td>\n",
       "      <td>Subject: Strategic Approach to Overcoming Import Restrictions for ...</td>\n",
       "      <td>Subject: Strategy for Overcoming Certification and Import Challeng...</td>\n",
       "      <td>✔️ [0.900]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         target_response  \\\n",
       "0  Subject: Follow-up on Endpoint Management Solution Discussion Dear...   \n",
       "1  Кампания \"Share a Coke\" была запущена Coca-Cola в 2011 году в Авст...   \n",
       "2  Creating a Facebook ad campaign within a specific budget and targe...   \n",
       "3  The delivery was scheduled for today, but due to a payment delay t...   \n",
       "4  Dear Ms. Amanda, I hope this email finds you well. I wanted to bri...   \n",
       "\n",
       "                                                              user_query  \\\n",
       "0  rewrite in professional \"as discusseed in last meeting with you an...   \n",
       "1                      расскажи про PR-кампанию Coca-Cola “Share a Coke\"   \n",
       "2  give me a facebook ads campaign for the next 7 days for canva pro ...   \n",
       "3  The delivery supposed to be today. Seems our payment delay to Lvio...   \n",
       "4  write a email to Ms, Amanda ; tell her, we have a way to overcome ...   \n",
       "\n",
       "                                                pii_str  \\\n",
       "0                                 effem||balaji||balaji   \n",
       "1                                             coca-cola   \n",
       "2                                         jordan||canva   \n",
       "3                               seagate||lviv||ms. chan   \n",
       "4  india||amanda||hermann(germany)||china||vims(france)   \n",
       "\n",
       "                                                             llm_request  \\\n",
       "0  Rewrite the following message in a professional tone suitable for ...   \n",
       "1  Please provide a detailed overview of a well-known beverage compan...   \n",
       "2  Design a 7-day Facebook Ads campaign plan to promote Canva Pro sub...   \n",
       "3  Draft a professional and concise message to inform a logistics or ...   \n",
       "4  Draft an professional email to Ms. Amanda explaining that, due to ...   \n",
       "\n",
       "                                                            llm_response  \\\n",
       "0  Subject: Follow-up on Account Maintenance Solution and Request Sta...   \n",
       "1  The “Share a Coke” campaign is a widely recognized marketing initi...   \n",
       "2  **7-Day Facebook Ads Campaign Plan for Canva Pro Subscriptions (Jo...   \n",
       "3  Subject: Urgent: Request to Reschedule Delivery Due to Payment Iss...   \n",
       "4  Subject: Strategic Approach to Overcoming Import Restrictions for ...   \n",
       "\n",
       "                                                                response  \\\n",
       "0  Subject: Follow-up on Account Maintenance Solution and Request Sta...   \n",
       "1  PR-кампания Coca-Cola “Share a Coke” является одним из наиболее из...   \n",
       "2  **7-Day Facebook Ads Campaign for Canva Pro Selling in Jordan** **...   \n",
       "3  Subject: Urgent: Rescheduling of Today's Delivery Due to Payment D...   \n",
       "4  Subject: Strategy for Overcoming Certification and Import Challeng...   \n",
       "\n",
       "  compute_overall_score  \n",
       "0            ✔️ [0.500]  \n",
       "1            ✔️ [1.000]  \n",
       "2            ✔️ [1.000]  \n",
       "3            ✔️ [1.000]  \n",
       "4            ✔️ [0.900]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style='\n",
       "                text-align: center;\n",
       "                font-size: 16px;\n",
       "                font-weight: bold;\n",
       "                color: #555;\n",
       "                margin: 10px 0;'>\n",
       "                ... 209 more rows not displayed ...\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(score=84.25, results=<list of 214 results>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(optimized_papillon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9940f47",
   "metadata": {},
   "source": [
    "## Performance Improvement Summary\n",
    "\n",
    "Display the improvement in overall score from baseline (80.76%) to optimized (84.25%) performance. This shows how GEPA optimization improved the system's ability to maintain response quality while better preserving user privacy.\n",
    "\n",
    "### Comparison: GEPA vs MIPROv2\n",
    "\n",
    "| Optimizer | Baseline | Optimized | Improvement |\n",
    "|-----------|----------|-----------|-------------|\n",
    "| GEPA | 80.76% | 84.25% | +3.49 pp |\n",
    "| MIPROv2 | 78.96% | 82.17% | +3.21 pp |\n",
    "\n",
    "*pp = percentage points*\n",
    "\n",
    "**Note on Training Budget:** The GEPA optimization in this notebook uses `max_full_evals=1` (a single full evaluation), which is a lightweight training budget for demonstration purposes. In contrast, the MIPROv2 papillon code uses `auto=\"heavy\"`, which is much more intensive and performs significantly more evaluations. Despite using a much smaller training budget, GEPA achieves comparable or better performance improvements, demonstrating its efficiency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
