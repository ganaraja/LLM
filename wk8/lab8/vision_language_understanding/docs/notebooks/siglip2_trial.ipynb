{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9adbf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- Many of the styles here are inspired by: \n",
       "    https://towardsdatascience.com/10-practical-tips-you-need-to-know-to-personalize-jupyter-notebook-fbd202777e20 \n",
       "\n",
       "\n",
       "    On the author's local machine, these exist in the custom.css file. However, in order to keep uniform look and feel, \n",
       "    and at the request of participants, I have added it to this common import-file here.\n",
       "\n",
       "    -->\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Lora:400,700|Montserrat:300\" rel=\"stylesheet\">\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Crimson+Pro&family=Literata&display=swap\" rel=\"stylesheet\">\n",
       "<style>\n",
       "\n",
       "\n",
       "#ipython_notebook::before{\n",
       " content:\"Neural Architectures\";\n",
       "        color: white;\n",
       "        font-weight: bold;\n",
       "        text-transform: uppercase;\n",
       "        font-family: 'Lora',serif;\n",
       "        font-size:16pt;\n",
       "        margin-bottom:15px;\n",
       "        margin-top:15px;\n",
       "\n",
       "}\n",
       "body > #header {\n",
       "    #background: #D15555;\n",
       "    background: linear-gradient(to bottom, indianred 0%, #fff 100%);\n",
       "    opacity: 0.8;\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       ".navbar-default .navbar-nav > li > a, #kernel_indicator {\n",
       "    color: white;\n",
       "    transition: all 0.25s;\n",
       "    font-size:10pt;\n",
       "    font-family: sans-serif;\n",
       "    font-weight:normal;\n",
       "}\n",
       ".navbar-default {\n",
       "    padding-left:100px;\n",
       "    background: none;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       "\n",
       "body > menubar-container {\n",
       "    background-color: wheat;\n",
       "}\n",
       "#ipython_notebook img{                                                                                        \n",
       "    display:block; \n",
       "\n",
       "    background: url(\"https://www.supportvectors.com/wp-content/uploads/2016/03/logo-poster-smaller.png\") no-repeat;\n",
       "    background-size: contain;\n",
       "\n",
       "    padding-left: 600px;\n",
       "    padding-right: 100px;\n",
       "\n",
       "    -moz-box-sizing: border-box;\n",
       "    box-sizing: border-box;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "body {\n",
       " #font-family:  'Literata', serif;\n",
       "    font-family:'Lora', san-serif;\n",
       "    text-align: justify;\n",
       "    font-weight: 400;\n",
       "    font-size: 12pt;\n",
       "}\n",
       "\n",
       "iframe{\n",
       "    width:100%;\n",
       "    min-height:600px;\n",
       "}\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "# font-family: 'Montserrat', sans-serif;\n",
       " font-family:'Lora', serif;\n",
       " font-weight: 200;\n",
       " text-transform: uppercase;\n",
       " color: #EC7063 ;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "    color: #000080;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       "#notebook_name {\n",
       "    font-weight: 600;\n",
       "    font-size:20pt;\n",
       "    text-variant:uppercase;\n",
       "    color: wheat; \n",
       "    margin-right:20px;\n",
       "    margin-left:-500px;\n",
       "}\n",
       "#notebook_name:hover {\n",
       "background-color: salmon;\n",
       "}\n",
       "\n",
       "\n",
       ".dataframe { /* dataframe atau table */\n",
       "    background: white;\n",
       "    box-shadow: 0px 1px 2px #bbb;\n",
       "}\n",
       ".dataframe thead th, .dataframe tbody td {\n",
       "    text-align: center;\n",
       "    padding: 1em;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       ".output {\n",
       "    align-items: center;\n",
       "}\n",
       "\n",
       "div.cell {\n",
       "    transition: all 0.25s;\n",
       "    border: none;\n",
       "    position: relative;\n",
       "    top: 0;\n",
       "}\n",
       "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
       "    border: none;\n",
       "    background: transparent;\n",
       "    box-shadow: 0 6px 18px #aaa;\n",
       "    z-index: 10;\n",
       "    top: -10px;\n",
       "}\n",
       ".CodeMirror pre, .CodeMirror-dialog, .CodeMirror-dialog .CodeMirror-search-field, .terminal-app .terminal {\n",
       "    font-family: 'Hack' , serif; \n",
       "    font-weight: 500;\n",
       "    font-size: 14pt;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "</style>    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "<div style=\"color:#aaa;font-size:8pt\">\n",
       "<hr/>\n",
       "&copy; SupportVectors. All rights reserved. <blockquote>This notebook is the intellectual property of SupportVectors, and part of its training material. \n",
       "Only the participants in SupportVectors workshops are allowed to study the notebooks for educational purposes currently, but is prohibited from copying or using it for any other purposes without written permission.\n",
       "\n",
       "<b> These notebooks are chapters and sections from Asif Qamar's textbook that he is writing on Data Science. So we request you to not circulate the material to others.</b>\n",
       " </blockquote>\n",
       " <hr/>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run supportvectors-common.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e27b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9ee0c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ckpt = \"google/siglip2-so400m-patch14-384\"\n",
    "pipe = pipeline(model=ckpt, task=\"zero-shot-image-classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed0e79a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = {\n",
    "    \"images\": [\n",
    "        \"https://huggingface.co/datasets/merve/coco/resolve/main/val2017/000000000285.jpg\", # bear\n",
    "        \"https://huggingface.co/datasets/merve/coco/resolve/main/val2017/000000000776.jpg\", # teddy bear\n",
    "    ],\n",
    "    \"texts\": [\n",
    "        \"bear looking into the camera\",\n",
    "        \"bear looking away from the camera\",\n",
    "        \"a bunch of teddy bears\",\n",
    "        \"two teddy bears\",\n",
    "        \"three teddy bears\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "outputs = pipe(inputs[\"images\"], candidate_labels=inputs[\"texts\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ee2087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.9468083381652832, 'label': 'bear looking into the camera'},\n",
       "  {'score': 0.5860347747802734, 'label': 'bear looking away from the camera'},\n",
       "  {'score': 3.622933945734985e-05, 'label': 'two teddy bears'},\n",
       "  {'score': 1.77714664459927e-05, 'label': 'three teddy bears'},\n",
       "  {'score': 1.7669732187641785e-05, 'label': 'a bunch of teddy bears'}],\n",
       " [{'score': 0.9882351160049438, 'label': 'a bunch of teddy bears'},\n",
       "  {'score': 0.943406879901886, 'label': 'three teddy bears'},\n",
       "  {'score': 0.06689281761646271, 'label': 'two teddy bears'},\n",
       "  {'score': 0.009915388189256191,\n",
       "   'label': 'bear looking away from the camera'},\n",
       "  {'score': 0.009330790489912033, 'label': 'bear looking into the camera'}]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ded42a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "ckpt = \"google/siglip2-base-patch16-224\"\n",
    "pipe = pipeline(model=ckpt, task=\"zero-shot-image-classification\")\n",
    "\n",
    "inputs = {\n",
    "    \"images\": [\n",
    "        \"https://huggingface.co/datasets/merve/coco/resolve/main/val2017/000000000285.jpg\", # bear\n",
    "        \"https://huggingface.co/datasets/merve/coco/resolve/main/val2017/000000000776.jpg\", # teddy bear\n",
    "    ],\n",
    "    \"texts\": [\n",
    "        \"bear looking into the camera\",\n",
    "        \"bear looking away from the camera\",\n",
    "        \"a bunch of teddy bears\",\n",
    "        \"two teddy bears\",\n",
    "        \"three teddy bears\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "outputs = pipe(inputs[\"images\"], candidate_labels=inputs[\"texts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "720181ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.679002046585083, 'label': 'bear looking into the camera'},\n",
       "  {'score': 0.24724067747592926, 'label': 'bear looking away from the camera'},\n",
       "  {'score': 0.002167385770007968, 'label': 'a bunch of teddy bears'},\n",
       "  {'score': 0.0007101988303475082, 'label': 'two teddy bears'},\n",
       "  {'score': 0.00029981607804074883, 'label': 'three teddy bears'}],\n",
       " [{'score': 0.9751574993133545, 'label': 'three teddy bears'},\n",
       "  {'score': 0.9591702818870544, 'label': 'a bunch of teddy bears'},\n",
       "  {'score': 0.9025977253913879, 'label': 'two teddy bears'},\n",
       "  {'score': 0.001824832521378994, 'label': 'bear looking into the camera'},\n",
       "  {'score': 0.0017922037513926625,\n",
       "   'label': 'bear looking away from the camera'}]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15d126c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "candidate_labels = [\"cats\", \"dogs\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "529d0e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "057a76b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.056640625, 'label': 'cats'},\n",
       " {'score': 0.00014019012451171875, 'label': 'dogs'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pipeline_1 = pipeline(task=\"zero-shot-image-classification\", model=\"google/siglip2-base-patch16-224\", device=0, dtype=torch.bfloat16)\n",
    "pipeline_1(image, candidate_labels=candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32b11563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.06005859375, 'label': 'cats'},\n",
       " {'score': 6.628036499023438e-05, 'label': 'dogs'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipeline_2 = pipeline(task=\"zero-shot-image-classification\", model=\"google/siglip2-so400m-patch14-384\", device=0, dtype=torch.bfloat16)\n",
    "pipeline_2(image, candidate_labels=candidate_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
