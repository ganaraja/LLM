{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b86a651b",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://supportvectors.ai/logo-poster-transparent.png\" width=\"400px\" style=\"opacity:0.7\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f65f282a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- Many of the styles here are inspired by: \n",
       "    https://towardsdatascience.com/10-practical-tips-you-need-to-know-to-personalize-jupyter-notebook-fbd202777e20 \n",
       "\n",
       "\n",
       "    On the author's local machine, these exist in the custom.css file. However, in order to keep uniform look and feel, \n",
       "    and at the request of participants, I have added it to this common import-file here.\n",
       "\n",
       "    -->\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Lora:400,700|Montserrat:300\" rel=\"stylesheet\">\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Crimson+Pro&family=Literata&display=swap\" rel=\"stylesheet\">\n",
       "<style>\n",
       "\n",
       "\n",
       "#ipython_notebook::before{\n",
       " content:\"Neural Architectures\";\n",
       "        color: white;\n",
       "        font-weight: bold;\n",
       "        text-transform: uppercase;\n",
       "        font-family: 'Lora',serif;\n",
       "        font-size:16pt;\n",
       "        margin-bottom:15px;\n",
       "        margin-top:15px;\n",
       "\n",
       "}\n",
       "body > #header {\n",
       "    #background: #D15555;\n",
       "    background: linear-gradient(to bottom, indianred 0%, #fff 100%);\n",
       "    opacity: 0.8;\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       ".navbar-default .navbar-nav > li > a, #kernel_indicator {\n",
       "    color: white;\n",
       "    transition: all 0.25s;\n",
       "    font-size:10pt;\n",
       "    font-family: sans-serif;\n",
       "    font-weight:normal;\n",
       "}\n",
       ".navbar-default {\n",
       "    padding-left:100px;\n",
       "    background: none;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       "\n",
       "body > menubar-container {\n",
       "    background-color: wheat;\n",
       "}\n",
       "#ipython_notebook img{                                                                                        \n",
       "    display:block; \n",
       "\n",
       "    background: url(\"https://www.supportvectors.com/wp-content/uploads/2016/03/logo-poster-smaller.png\") no-repeat;\n",
       "    background-size: contain;\n",
       "\n",
       "    padding-left: 600px;\n",
       "    padding-right: 100px;\n",
       "\n",
       "    -moz-box-sizing: border-box;\n",
       "    box-sizing: border-box;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "body {\n",
       " #font-family:  'Literata', serif;\n",
       "    font-family:'Lora', san-serif;\n",
       "    text-align: justify;\n",
       "    font-weight: 400;\n",
       "    font-size: 12pt;\n",
       "}\n",
       "\n",
       "iframe{\n",
       "    width:100%;\n",
       "    min-height:600px;\n",
       "}\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "# font-family: 'Montserrat', sans-serif;\n",
       " font-family:'Lora', serif;\n",
       " font-weight: 200;\n",
       " text-transform: uppercase;\n",
       " color: #EC7063 ;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "    color: #000080;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       "#notebook_name {\n",
       "    font-weight: 600;\n",
       "    font-size:20pt;\n",
       "    text-variant:uppercase;\n",
       "    color: wheat; \n",
       "    margin-right:20px;\n",
       "    margin-left:-500px;\n",
       "}\n",
       "#notebook_name:hover {\n",
       "background-color: salmon;\n",
       "}\n",
       "\n",
       "\n",
       ".dataframe { /* dataframe atau table */\n",
       "    background: white;\n",
       "    box-shadow: 0px 1px 2px #bbb;\n",
       "}\n",
       ".dataframe thead th, .dataframe tbody td {\n",
       "    text-align: center;\n",
       "    padding: 1em;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       ".output {\n",
       "    align-items: center;\n",
       "}\n",
       "\n",
       "div.cell {\n",
       "    transition: all 0.25s;\n",
       "    border: none;\n",
       "    position: relative;\n",
       "    top: 0;\n",
       "}\n",
       "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
       "    border: none;\n",
       "    background: transparent;\n",
       "    box-shadow: 0 6px 18px #aaa;\n",
       "    z-index: 10;\n",
       "    top: -10px;\n",
       "}\n",
       ".CodeMirror pre, .CodeMirror-dialog, .CodeMirror-dialog .CodeMirror-search-field, .terminal-app .terminal {\n",
       "    font-family: 'Hack' , serif; \n",
       "    font-weight: 500;\n",
       "    font-size: 14pt;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "</style>    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "<div style=\"color:#aaa;font-size:8pt\">\n",
       "<hr/>\n",
       "&copy; SupportVectors. All rights reserved. <blockquote>This notebook is the intellectual property of SupportVectors, and part of its training material. \n",
       "Only the participants in SupportVectors workshops are allowed to study the notebooks for educational purposes currently, but is prohibited from copying or using it for any other purposes without written permission.\n",
       "\n",
       "<b> These notebooks are chapters and sections from Asif Qamar's textbook that he is writing on Data Science. So we request you to not circulate the material to others.</b>\n",
       " </blockquote>\n",
       " <hr/>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run supportvectors-common.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965aa3ac",
   "metadata": {},
   "source": [
    "# Contextual and Late Chunking\n",
    "\n",
    "This demo demonstrates how semantic chunking can lose important context (like pronoun references) and how contextual chunking and late chunking can restore this lost context.\n",
    "\n",
    "We'll use a sample text with pronoun references that will be lost during semantic chunking but restored through contextual or late chunking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e4fb08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7da81ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sample text loaded with pronoun references:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Sample text loaded with pronoun references:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Machine Learning Fundamentals\n",
       "\n",
       "Neural networks are computational models inspired by biological neural networks. They consist of interconnected \n",
       "nodes called neurons that process information through we<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Machine Learning Fundamentals\n",
       "\n",
       "Neural networks are computational models inspired by biological neural networks. They consist of interconnected \n",
       "nodes called neurons that process information through we\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample text with pronoun references that will be lost during semantic chunking\n",
    "sample_text = \"\"\"\n",
    "Machine Learning Fundamentals\n",
    "\n",
    "Neural networks are computational models inspired by biological neural networks. They consist of interconnected nodes called neurons that process information through weighted connections. The basic building block is the perceptron, which takes multiple inputs, applies weights, and produces an output through an activation function.\n",
    "\n",
    "The learning process in neural networks involves adjusting these weights based on training data. This is typically done through backpropagation, where the network calculates the gradient of the loss function with respect to each weight and updates them accordingly. The learning rate determines how much the weights are adjusted in each iteration.\n",
    "\n",
    "Deep learning extends this concept by using multiple hidden layers between the input and output layers. Each layer can learn increasingly complex features, with early layers detecting simple patterns like edges and later layers combining these into more complex concepts. This hierarchical feature learning is what makes deep neural networks so powerful for tasks like image recognition and natural language processing.\n",
    "\n",
    "Advanced Optimization Techniques\n",
    "\n",
    "While basic gradient descent works for simple problems, more sophisticated optimization algorithms have been developed to improve training efficiency and convergence. These techniques address common challenges like getting stuck in local minima, slow convergence, and handling different scales of gradients across parameters.\n",
    "\n",
    "One popular approach is adaptive learning rates, where the learning rate is adjusted for each parameter based on its historical gradients. Adam (Adaptive Moment Estimation) combines the benefits of momentum and adaptive learning rates by maintaining exponentially decaying averages of both gradients and squared gradients. This allows the algorithm to automatically adjust the learning rate for each parameter, often leading to faster convergence and better performance.\n",
    "\n",
    "Another important technique is regularization, which helps prevent overfitting by adding constraints to the model. L1 regularization adds a penalty proportional to the sum of absolute values of weights, encouraging sparsity. L2 regularization adds a penalty proportional to the sum of squared weights, encouraging smaller weights. Dropout randomly sets a fraction of input units to zero during training, forcing the network to not rely on any single neuron and improving generalization.\n",
    "\n",
    "Batch normalization is another crucial technique that normalizes the inputs to each layer by adjusting and scaling the activations. This helps stabilize training by reducing internal covariate shift, allowing for higher learning rates and making the network less sensitive to initialization. It also acts as a regularizer, reducing the need for dropout in some cases.\n",
    "\"\"\"\n",
    "\n",
    "rprint(\"Sample text loaded with pronoun references:\")\n",
    "rprint(sample_text[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a58a42f",
   "metadata": {},
   "source": [
    "## Step 1: Use Entire Document as Single Parent Chunk\n",
    "\n",
    "We'll use the entire document as one parent chunk and then apply semantic chunking to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e7287f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Using entire document as single parent chunk:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Using entire document as single parent chunk:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Length: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2823</span> characters\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Length: \u001b[1;36m2823\u001b[0m characters\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preview: Machine Learning Fundamentals\n",
       "\n",
       "Neural networks are computational models inspired by biological neural networks. They consist of interconnected \n",
       "nodes called neurons that process information through wei<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Preview: Machine Learning Fundamentals\n",
       "\n",
       "Neural networks are computational models inspired by biological neural networks. They consist of interconnected \n",
       "nodes called neurons that process information through wei\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use entire document as single parent chunk\n",
    "parent_chunk = {\n",
    "    \"id\": 0,\n",
    "    \"text\": sample_text.strip(),\n",
    "    \"title\": \"Complete Document\"\n",
    "}\n",
    "\n",
    "rprint(\"Using entire document as single parent chunk:\")\n",
    "rprint(f\"Length: {len(parent_chunk['text'])} characters\")\n",
    "rprint(f\"Preview: {parent_chunk['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71e9b70",
   "metadata": {},
   "source": [
    "## Step 2: Semantic Chunking\n",
    "\n",
    "Use `chonkie` to semantically chunk each parent chunk. This will break down the text into smaller, semantically coherent pieces, but may lose important context like pronoun references.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e6d2802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Created <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> semantic chunks from the complete document\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Created \u001b[1;36m10\u001b[0m semantic chunks from the complete document\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Semantic chunks preview:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Semantic chunks preview:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Semantic Chunk <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Semantic Chunk \u001b[1;36m0\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Text: Machine Learning Fundamentals\n",
       "\n",
       "Neural networks are computational models inspired by biological neura<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Text: Machine Learning Fundamentals\n",
       "\n",
       "Neural networks are computational models inspired by biological neura\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Start: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, End: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">713</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Start: \u001b[1;36m0\u001b[0m, End: \u001b[1;36m713\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Semantic Chunk <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Semantic Chunk \u001b[1;36m1\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Text: \n",
       "Deep learning extends this concept by using multiple hidden layers between the input and output lay<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Text: \n",
       "Deep learning extends this concept by using multiple hidden layers between the input and output lay\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Start: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">713</span>, End: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">818</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Start: \u001b[1;36m713\u001b[0m, End: \u001b[1;36m818\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Semantic Chunk <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Semantic Chunk \u001b[1;36m2\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Text: Each layer can learn increasingly complex features, with early layers detecting simple patterns like<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Text: Each layer can learn increasingly complex features, with early layers detecting simple patterns like\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Start: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">818</span>, End: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1134</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Start: \u001b[1;36m818\u001b[0m, End: \u001b[1;36m1134\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Semantic Chunk <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Semantic Chunk \u001b[1;36m3\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Text: \n",
       "Advanced Optimization Techniques\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Text: \n",
       "Advanced Optimization Techniques\n",
       "\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Start: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1134</span>, End: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1168</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Start: \u001b[1;36m1134\u001b[0m, End: \u001b[1;36m1168\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Semantic Chunk <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Semantic Chunk \u001b[1;36m4\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Text: \n",
       "While basic gradient descent works for simple problems, more sophisticated optimization algorithms <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Text: \n",
       "While basic gradient descent works for simple problems, more sophisticated optimization algorithms \u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Start: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1168</span>, End: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1336</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Start: \u001b[1;36m1168\u001b[0m, End: \u001b[1;36m1336\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chonkie import SemanticChunker\n",
    "\n",
    "# Initialize semantic chunker\n",
    "semantic_chunker = SemanticChunker()\n",
    "\n",
    "# Process the single parent chunk\n",
    "semantic_chunks = []\n",
    "parent_chunk_dict = {\n",
    "    \"id\": parent_chunk[\"id\"],\n",
    "    \"text\": parent_chunk[\"text\"],\n",
    "    \"title\": parent_chunk[\"title\"],\n",
    "    \"semantic_chunks\": []\n",
    "}\n",
    "\n",
    "# Get semantic chunks for the parent\n",
    "sem_chunks = semantic_chunker.chunk(parent_chunk[\"text\"])\n",
    "\n",
    "for i, sc in enumerate(sem_chunks):\n",
    "    semantic_chunk_dict_item = {\n",
    "        \"id\": i,\n",
    "        \"text\": sc.text,\n",
    "        \"start_char\": sc.start_index,\n",
    "        \"end_char\": sc.end_index\n",
    "    }\n",
    "    parent_chunk_dict[\"semantic_chunks\"].append(semantic_chunk_dict_item)\n",
    "    \n",
    "    # Also maintain a flat list for contextual chunking\n",
    "    semantic_chunks.append({\n",
    "        \"chunk_id\": i,\n",
    "        \"chunk\": sc,\n",
    "        \"parent_id\": parent_chunk[\"id\"],\n",
    "        \"parent_chunk\": parent_chunk\n",
    "    })\n",
    "\n",
    "rprint(f\"Created {len(semantic_chunks)} semantic chunks from the complete document\")\n",
    "rprint(\"\\nSemantic chunks preview:\")\n",
    "for i, sc in enumerate(semantic_chunks[:5]):  # Show first 5 chunks\n",
    "    rprint(f\"\\nSemantic Chunk {i}:\")\n",
    "    rprint(f\"Text: {sc['chunk'].text[:100]}...\")\n",
    "    rprint(f\"Start: {sc['chunk'].start_index}, End: {sc['chunk'].end_index}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3e75d2",
   "metadata": {},
   "source": [
    "## Step 3: Identify Pronoun References Lost in Semantic Chunking\n",
    "\n",
    "Let's examine some semantic chunks to see where pronoun references like \"it\", \"this\", \"they\" lose their context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35e7c1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> semantic chunks with pronoun references:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Found \u001b[1;36m6\u001b[0m semantic chunks with pronoun references:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Chunk <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Chunk \u001b[1;36m0\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pronouns found: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'this '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'they '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'these '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'that '</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pronouns found: \u001b[1m[\u001b[0m\u001b[32m'this '\u001b[0m, \u001b[32m'they '\u001b[0m, \u001b[32m'these '\u001b[0m, \u001b[32m'that '\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Text: Machine Learning Fundamentals\n",
       "\n",
       "Neural networks are computational models inspired by biological neural networks. They consist of interconnected \n",
       "nodes called neurons that process information through weighted connections. The basic building block is the \n",
       "perceptron, which takes multiple inputs, applies weights, and produces an output through an activation function.\n",
       "\n",
       "The learning process in neural networks involves adjusting these weights based on training data. This is typically \n",
       "done through backpropagation, where the network calculates the gradient of the loss function with respect to each \n",
       "weight and updates them accordingly. The learning rate determines how much the weights are adjusted in each \n",
       "iteration.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Text: Machine Learning Fundamentals\n",
       "\n",
       "Neural networks are computational models inspired by biological neural networks. They consist of interconnected \n",
       "nodes called neurons that process information through weighted connections. The basic building block is the \n",
       "perceptron, which takes multiple inputs, applies weights, and produces an output through an activation function.\n",
       "\n",
       "The learning process in neural networks involves adjusting these weights based on training data. This is typically \n",
       "done through backpropagation, where the network calculates the gradient of the loss function with respect to each \n",
       "weight and updates them accordingly. The learning rate determines how much the weights are adjusted in each \n",
       "iteration.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">------------------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "------------------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Chunk <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Chunk \u001b[1;36m1\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pronouns found: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'this '</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pronouns found: \u001b[1m[\u001b[0m\u001b[32m'this '\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Text: \n",
       "Deep learning extends this concept by using multiple hidden layers between the input and output layers. \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Text: \n",
       "Deep learning extends this concept by using multiple hidden layers between the input and output layers. \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">------------------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "------------------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Chunk <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Chunk \u001b[1;36m2\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pronouns found: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'this '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'these '</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pronouns found: \u001b[1m[\u001b[0m\u001b[32m'this '\u001b[0m, \u001b[32m'these '\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Text: Each layer can learn increasingly complex features, with early layers detecting simple patterns like edges \n",
       "and later layers combining these into more complex concepts. This hierarchical feature learning is what makes deep \n",
       "neural networks so powerful for tasks like image recognition and natural language processing.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Text: Each layer can learn increasingly complex features, with early layers detecting simple patterns like edges \n",
       "and later layers combining these into more complex concepts. This hierarchical feature learning is what makes deep \n",
       "neural networks so powerful for tasks like image recognition and natural language processing.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">------------------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "------------------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find semantic chunks with pronoun references\n",
    "pronoun_chunks = []\n",
    "\n",
    "for i, sc in enumerate(semantic_chunks):\n",
    "    text = sc['chunk'].text.lower()\n",
    "    pronouns = ['it ', 'this ', 'they ', 'these ', 'that ', 'those ']\n",
    "    found_pronouns = [p for p in pronouns if p in text]\n",
    "    \n",
    "    if found_pronouns:\n",
    "        pronoun_chunks.append({\n",
    "            'chunk_id': i,\n",
    "            'text': sc['chunk'].text,\n",
    "            'pronouns': found_pronouns\n",
    "        })\n",
    "\n",
    "rprint(f\"Found {len(pronoun_chunks)} semantic chunks with pronoun references:\")\n",
    "rprint(\"\\n\" + \"=\"*80)\n",
    "\n",
    "for chunk in pronoun_chunks[:3]:  # Show first 3 examples\n",
    "    rprint(f\"\\nChunk {chunk['chunk_id']}:\")\n",
    "    rprint(f\"Pronouns found: {chunk['pronouns']}\")\n",
    "    rprint(f\"Text: {chunk['text']}\")\n",
    "    rprint(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647a3737",
   "metadata": {},
   "source": [
    "## Step 4: Contextual Chunking\n",
    "\n",
    "Now we'll use an LLM to enrich each semantic chunk with context from its parent chunk, resolving pronoun references and making each chunk self-standing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44a80910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing semantic chunks with contextual chunking<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing semantic chunks with contextual chunking\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">============================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "============================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Chunk <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> <span style=\"font-weight: bold\">(</span>from Complete Document<span style=\"font-weight: bold\">)</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Chunk \u001b[1;36m0\u001b[0m \u001b[1m(\u001b[0mfrom Complete Document\u001b[1m)\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Original: Machine Learning Fundamentals\n",
       "\n",
       "Neural networks are computational models inspired by biological neura<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Original: Machine Learning Fundamentals\n",
       "\n",
       "Neural networks are computational models inspired by biological neura\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Contextual: **Machine Learning Fundamentals**\n",
       "\n",
       "Neural networks are computational models inspired by biological n<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Contextual: **Machine Learning Fundamentals**\n",
       "\n",
       "Neural networks are computational models inspired by biological n\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Chunk <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"font-weight: bold\">(</span>from Complete Document<span style=\"font-weight: bold\">)</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Chunk \u001b[1;36m1\u001b[0m \u001b[1m(\u001b[0mfrom Complete Document\u001b[1m)\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Original: \n",
       "Deep learning extends this concept by using multiple hidden layers between the input and output lay<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Original: \n",
       "Deep learning extends this concept by using multiple hidden layers between the input and output lay\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Contextual: Deep learning extends the concept of neural networks, which consist of interconnected neurons that p<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Contextual: Deep learning extends the concept of neural networks, which consist of interconnected neurons that p\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Chunk <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> <span style=\"font-weight: bold\">(</span>from Complete Document<span style=\"font-weight: bold\">)</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Chunk \u001b[1;36m2\u001b[0m \u001b[1m(\u001b[0mfrom Complete Document\u001b[1m)\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Original: Each layer can learn increasingly complex features, with early layers detecting simple patterns like<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Original: Each layer can learn increasingly complex features, with early layers detecting simple patterns like\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Contextual: Deep neural networks are computational models that utilize several hidden layers between the input a<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Contextual: Deep neural networks are computational models that utilize several hidden layers between the input a\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Completed contextual chunking for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> chunks\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Completed contextual chunking for \u001b[1;36m10\u001b[0m chunks\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client (using Ollama)\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"ollama\"\n",
    ")\n",
    "\n",
    "# Contextual chunking prompt\n",
    "contextual_prompt = \"\"\"\n",
    "Here is the parent section: {parent_text}\n",
    "\n",
    "Now here is the semantic chunk: {semantic_text}\n",
    "\n",
    "Please produce an enriched chunk which retains the semantic chunk but adds any necessary context from the parent so that the chunk is self-standing. Pay special attention to resolving any pronoun references (it, this, they, etc.) by replacing them with their proper antecedents.\n",
    "\n",
    "Do not add anything that is not needed to make the chunk self-standing.\n",
    "\"\"\"\n",
    "\n",
    "# Process each semantic chunk\n",
    "contextual_chunks = []\n",
    "\n",
    "rprint(\"Processing semantic chunks with contextual chunking...\")\n",
    "rprint(\"=\"*60)\n",
    "\n",
    "for i, sc in enumerate(semantic_chunks):\n",
    "    parent_text = sc['parent_chunk']['text']\n",
    "    semantic_text = sc['chunk'].text\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-oss:20b\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": contextual_prompt.format(parent_text=parent_text, semantic_text=semantic_text)},\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        contextual_chunk = response.choices[0].message.content\n",
    "        \n",
    "        contextual_chunks.append({\n",
    "            \"chunk_id\": sc['chunk_id'],\n",
    "            \"parent_id\": sc['parent_id'],\n",
    "            \"original_semantic_chunk\": semantic_text,\n",
    "            \"contextual_chunk\": contextual_chunk,\n",
    "            \"parent_title\": sc['parent_chunk']['title']\n",
    "        })\n",
    "        \n",
    "        # Show progress for first few chunks\n",
    "        if i < 3:\n",
    "            rprint(f\"\\nChunk {i} (from {sc['parent_chunk']['title']}):\")\n",
    "            rprint(f\"Original: {semantic_text[:100]}...\")\n",
    "            rprint(f\"Contextual: {contextual_chunk[:100]}...\")\n",
    "            rprint(\"-\" * 40)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk {i}: {e}\")\n",
    "        contextual_chunks.append({\n",
    "            \"chunk_id\": sc['chunk_id'],\n",
    "            \"parent_id\": sc['parent_id'],\n",
    "            \"original_semantic_chunk\": semantic_text,\n",
    "            \"contextual_chunk\": semantic_text,  # fallback to original\n",
    "            \"parent_title\": sc['parent_chunk']['title']\n",
    "        })\n",
    "\n",
    "rprint(f\"\\nCompleted contextual chunking for {len(contextual_chunks)} chunks\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f797b0b",
   "metadata": {},
   "source": [
    "## Step 5: Compare Original vs Contextual Chunks\n",
    "\n",
    "Let's compare some of the original semantic chunks with their contextual versions to see how pronoun references were resolved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89aa9427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">COMPARISON: Original Semantic Chunks vs Contextual Chunks\n",
       "</pre>\n"
      ],
      "text/plain": [
       "COMPARISON: Original Semantic Chunks vs Contextual Chunks\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Chunk <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Chunk \u001b[1;36m0\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pronouns found in original: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'this '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'they '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'these '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'that '</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pronouns found in original: \u001b[1m[\u001b[0m\u001b[32m'this '\u001b[0m, \u001b[32m'they '\u001b[0m, \u001b[32m'these '\u001b[0m, \u001b[32m'that '\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "ORIGINAL SEMANTIC CHUNK:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "ORIGINAL SEMANTIC CHUNK:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">'Machine Learning Fundamentals\n",
       "\n",
       "Neural networks are computational models inspired by biological neural networks. They consist of interconnected \n",
       "nodes called neurons that process information through weighted connections. The basic building block is the \n",
       "perceptron, which takes multiple inputs, applies weights, and produces an output through an activation function.\n",
       "\n",
       "The learning process in neural networks involves adjusting these weights based on training data. This is typically \n",
       "done through backpropagation, where the network calculates the gradient of the loss function with respect to each \n",
       "weight and updates them accordingly. The learning rate determines how much the weights are adjusted in each \n",
       "iteration.\n",
       "'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "'Machine Learning Fundamentals\n",
       "\n",
       "Neural networks are computational models inspired by biological neural networks. They consist of interconnected \n",
       "nodes called neurons that process information through weighted connections. The basic building block is the \n",
       "perceptron, which takes multiple inputs, applies weights, and produces an output through an activation function.\n",
       "\n",
       "The learning process in neural networks involves adjusting these weights based on training data. This is typically \n",
       "done through backpropagation, where the network calculates the gradient of the loss function with respect to each \n",
       "weight and updates them accordingly. The learning rate determines how much the weights are adjusted in each \n",
       "iteration.\n",
       "'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "CONTEXTUAL CHUNK:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "CONTEXTUAL CHUNK:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">'**Machine Learning Fundamentals**\n",
       "\n",
       "Neural networks are computational models inspired by biological neural networks. Each neural network consists of \n",
       "interconnected nodes called neurons that process information through weighted connections. The basic building block\n",
       "of a neural network is the perceptron; a perceptron takes multiple inputs, applies a weight to each input, and \n",
       "produces an output through an activation function.\n",
       "\n",
       "The learning process of a neural network involves adjusting the weighted connections based on training data. This \n",
       "adjustment is typically performed using backpropagation, in which the network computes the gradient of the loss \n",
       "function with respect to each weight and then updates each weight in the direction that reduces the loss. The \n",
       "update rule is often a variant of gradient descent, and the learning rate controls the magnitude of each weight \n",
       "adjustment during each iteration.'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "'**Machine Learning Fundamentals**\n",
       "\n",
       "Neural networks are computational models inspired by biological neural networks. Each neural network consists of \n",
       "interconnected nodes called neurons that process information through weighted connections. The basic building block\n",
       "of a neural network is the perceptron; a perceptron takes multiple inputs, applies a weight to each input, and \n",
       "produces an output through an activation function.\n",
       "\n",
       "The learning process of a neural network involves adjusting the weighted connections based on training data. This \n",
       "adjustment is typically performed using backpropagation, in which the network computes the gradient of the loss \n",
       "function with respect to each weight and then updates each weight in the direction that reduces the loss. The \n",
       "update rule is often a variant of gradient descent, and the learning rate controls the magnitude of each weight \n",
       "adjustment during each iteration.'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "============================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "============================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Chunk <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Chunk \u001b[1;36m1\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pronouns found in original: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'this '</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pronouns found in original: \u001b[1m[\u001b[0m\u001b[32m'this '\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "ORIGINAL SEMANTIC CHUNK:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "ORIGINAL SEMANTIC CHUNK:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">'\n",
       "Deep learning extends this concept by using multiple hidden layers between the input and output layers. '\n",
       "</pre>\n"
      ],
      "text/plain": [
       "'\n",
       "Deep learning extends this concept by using multiple hidden layers between the input and output layers. '\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "CONTEXTUAL CHUNK:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "CONTEXTUAL CHUNK:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Deep learning extends the concept of neural networks, which consist of interconnected neurons that process </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information through weighted connections, by using multiple hidden layers positioned between the input layer and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">output layer. Each hidden layer learns increasingly complex features, allowing the network to progressively combine</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">simple patterns (such as edges) into more abstract concepts.'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Deep learning extends the concept of neural networks, which consist of interconnected neurons that process \u001b[0m\n",
       "\u001b[32minformation through weighted connections, by using multiple hidden layers positioned between the input layer and \u001b[0m\n",
       "\u001b[32moutput layer. Each hidden layer learns increasingly complex features, allowing the network to progressively combine\u001b[0m\n",
       "\u001b[32msimple patterns \u001b[0m\u001b[32m(\u001b[0m\u001b[32msuch as edges\u001b[0m\u001b[32m)\u001b[0m\u001b[32m into more abstract concepts.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "============================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "============================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare original vs contextual chunks, focusing on those with pronoun references\n",
    "rprint(\"COMPARISON: Original Semantic Chunks vs Contextual Chunks\")\n",
    "rprint(\"=\"*80)\n",
    "\n",
    "# Focus on chunks that originally had pronoun references\n",
    "for pronoun_chunk in pronoun_chunks[:2]:  # Show first 2 examples\n",
    "    chunk_id = pronoun_chunk['chunk_id']\n",
    "    \n",
    "    # Find the corresponding contextual chunk\n",
    "    contextual_chunk = next((cc for cc in contextual_chunks if cc['chunk_id'] == chunk_id), None)\n",
    "    \n",
    "    if contextual_chunk:\n",
    "        rprint(f\"\\nChunk {chunk_id}:\")\n",
    "        rprint(f\"Pronouns found in original: {pronoun_chunk['pronouns']}\")\n",
    "        rprint(\"\\nORIGINAL SEMANTIC CHUNK:\")\n",
    "        rprint(f\"'{contextual_chunk['original_semantic_chunk']}'\")\n",
    "        rprint(\"\\nCONTEXTUAL CHUNK:\")\n",
    "        rprint(f\"'{contextual_chunk['contextual_chunk']}'\")\n",
    "        rprint(\"\\n\" + \"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae56a01f",
   "metadata": {},
   "source": [
    "## Step 6: Late Chunking\n",
    "\n",
    "Now let's implement late chunking as an alternative approach. Late chunking uses embeddings to capture context from the parent chunk and associate it with each semantic chunk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "427c0c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading embedding model: jinaai/jina-embeddings-v2-base-en\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading embedding model: jinaai/jina-embeddings-v2-base-en\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Late chunking implementation ready!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Late chunking implementation ready!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load embedding model\n",
    "model_name = \"jinaai/jina-embeddings-v2-base-en\"\n",
    "rprint(f\"Loading embedding model: {model_name}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_name, trust_remote_code=True, output_hidden_states=True)\n",
    "\n",
    "def late_chunk_parent(parent_chunk):\n",
    "    \"\"\"\n",
    "    parent_chunk: dict with keys {id, text, semantic_chunks: List[{start_char, end_char, text, id}]}\n",
    "    Returns enriched semantic chunks with embeddings from parent context.\n",
    "    \"\"\"\n",
    "    text = parent_chunk[\"text\"]\n",
    "    sem_chunks = parent_chunk[\"semantic_chunks\"]\n",
    "\n",
    "    # Tokenize + embed the *parent chunk text only*\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=False, return_offsets_mapping=True)\n",
    "    # Save offsets separately\n",
    "    offsets = inputs.pop(\"offset_mapping\")[0].tolist()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    token_embs = outputs.last_hidden_state.squeeze(0)\n",
    "\n",
    "    enriched_semantics = []\n",
    "    for sc in sem_chunks:\n",
    "        s, e = sc[\"start_char\"], sc[\"end_char\"]\n",
    "        indices = [i for i, (ts, te) in enumerate(offsets) if te > s and ts < e]\n",
    "        if not indices:\n",
    "            # If no tokens found, use mean of all parent embeddings\n",
    "            emb = token_embs.mean(dim=0).cpu().numpy()\n",
    "        else:\n",
    "            emb = token_embs[indices].mean(dim=0).cpu().numpy()\n",
    "            \n",
    "        enriched_semantics.append({\n",
    "            \"semantic_id\": sc[\"id\"],\n",
    "            \"parent_id\": parent_chunk[\"id\"],\n",
    "            \"embedding\": emb.tolist(),\n",
    "            \"text\": sc[\"text\"],\n",
    "            \"parent_text\": text,\n",
    "            \"num_tokens\": len(indices) if indices else 0\n",
    "        })\n",
    "    return enriched_semantics\n",
    "\n",
    "rprint(\"Late chunking implementation ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4727efa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing parent chunk with late chunking<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing parent chunk with late chunking\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">==================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "==================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing parent chunk: Complete Document\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing parent chunk: Complete Document\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Example late chunks from Complete Document:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Example late chunks from Complete Document:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Late Chunk <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Late Chunk \u001b[1;36m0\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Text: Machine Learning Fundamentals\n",
       "\n",
       "Neural networks are computational models inspired by biological neura<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Text: Machine Learning Fundamentals\n",
       "\n",
       "Neural networks are computational models inspired by biological neura\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Embedding dimension: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Embedding dimension: \u001b[1;36m768\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tokens used: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">118</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Tokens used: \u001b[1;36m118\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Late Chunk <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Late Chunk \u001b[1;36m1\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Text: \n",
       "Deep learning extends this concept by using multiple hidden layers between the input and output lay<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Text: \n",
       "Deep learning extends this concept by using multiple hidden layers between the input and output lay\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Embedding dimension: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Embedding dimension: \u001b[1;36m768\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tokens used: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Tokens used: \u001b[1;36m17\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Late Chunk <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Late Chunk \u001b[1;36m2\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Text: Each layer can learn increasingly complex features, with early layers detecting simple patterns like<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Text: Each layer can learn increasingly complex features, with early layers detecting simple patterns like\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Embedding dimension: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Embedding dimension: \u001b[1;36m768\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tokens used: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Tokens used: \u001b[1;36m48\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Completed late chunking for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> chunks\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Completed late chunking for \u001b[1;36m10\u001b[0m chunks\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process the single parent chunk with late chunking\n",
    "rprint(\"Processing parent chunk with late chunking...\")\n",
    "rprint(\"=\"*50)\n",
    "\n",
    "rprint(f\"Processing parent chunk: {parent_chunk_dict['title']}\")\n",
    "enriched_semantics = late_chunk_parent(parent_chunk_dict)\n",
    "all_late_chunks = enriched_semantics\n",
    "\n",
    "rprint(f\"\\nExample late chunks from {parent_chunk_dict['title']}:\")\n",
    "for i, es in enumerate(enriched_semantics[:3]):\n",
    "    rprint(f\"\\nLate Chunk {i}:\")\n",
    "    rprint(f\"Text: {es['text'][:100]}...\")\n",
    "    rprint(f\"Embedding dimension: {len(es['embedding'])}\")\n",
    "    rprint(f\"Tokens used: {es['num_tokens']}\")\n",
    "\n",
    "rprint(f\"\\nCompleted late chunking for {len(all_late_chunks)} chunks\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
