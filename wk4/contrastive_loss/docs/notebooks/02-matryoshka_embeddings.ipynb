{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://supportvectors.ai/logo-poster-transparent.png\" width=400px style=\"opacity:0.8\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- Many of the styles here are inspired by: \n",
       "    https://towardsdatascience.com/10-practical-tips-you-need-to-know-to-personalize-jupyter-notebook-fbd202777e20 \n",
       "\n",
       "\n",
       "    On the author's local machine, these exist in the custom.css file. However, in order to keep uniform look and feel, \n",
       "    and at the request of participants, I have added it to this common import-file here.\n",
       "\n",
       "    -->\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Lora:400,700|Montserrat:300\" rel=\"stylesheet\">\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Crimson+Pro&family=Literata&display=swap\" rel=\"stylesheet\">\n",
       "<style>\n",
       "\n",
       "\n",
       "#ipython_notebook::before{\n",
       " content:\"Neural Architectures\";\n",
       "        color: white;\n",
       "        font-weight: bold;\n",
       "        text-transform: uppercase;\n",
       "        font-family: 'Lora',serif;\n",
       "        font-size:16pt;\n",
       "        margin-bottom:15px;\n",
       "        margin-top:15px;\n",
       "\n",
       "}\n",
       "body > #header {\n",
       "    #background: #D15555;\n",
       "    background: linear-gradient(to bottom, indianred 0%, #fff 100%);\n",
       "    opacity: 0.8;\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       ".navbar-default .navbar-nav > li > a, #kernel_indicator {\n",
       "    color: white;\n",
       "    transition: all 0.25s;\n",
       "    font-size:10pt;\n",
       "    font-family: sans-serif;\n",
       "    font-weight:normal;\n",
       "}\n",
       ".navbar-default {\n",
       "    padding-left:100px;\n",
       "    background: none;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       "\n",
       "body > menubar-container {\n",
       "    background-color: wheat;\n",
       "}\n",
       "#ipython_notebook img{                                                                                        \n",
       "    display:block; \n",
       "\n",
       "    background: url(\"https://www.supportvectors.com/wp-content/uploads/2016/03/logo-poster-smaller.png\") no-repeat;\n",
       "    background-size: contain;\n",
       "\n",
       "    padding-left: 600px;\n",
       "    padding-right: 100px;\n",
       "\n",
       "    -moz-box-sizing: border-box;\n",
       "    box-sizing: border-box;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "body {\n",
       " #font-family:  'Literata', serif;\n",
       "    font-family:'Lora', san-serif;\n",
       "    text-align: justify;\n",
       "    font-weight: 400;\n",
       "    font-size: 12pt;\n",
       "}\n",
       "\n",
       "iframe{\n",
       "    width:100%;\n",
       "    min-height:600px;\n",
       "}\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "# font-family: 'Montserrat', sans-serif;\n",
       " font-family:'Lora', serif;\n",
       " font-weight: 200;\n",
       " text-transform: uppercase;\n",
       " color: #EC7063 ;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "    color: #000080;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       "#notebook_name {\n",
       "    font-weight: 600;\n",
       "    font-size:20pt;\n",
       "    text-variant:uppercase;\n",
       "    color: wheat; \n",
       "    margin-right:20px;\n",
       "    margin-left:-500px;\n",
       "}\n",
       "#notebook_name:hover {\n",
       "background-color: salmon;\n",
       "}\n",
       "\n",
       "\n",
       ".dataframe { /* dataframe atau table */\n",
       "    background: white;\n",
       "    box-shadow: 0px 1px 2px #bbb;\n",
       "}\n",
       ".dataframe thead th, .dataframe tbody td {\n",
       "    text-align: center;\n",
       "    padding: 1em;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       ".output {\n",
       "    align-items: center;\n",
       "}\n",
       "\n",
       "div.cell {\n",
       "    transition: all 0.25s;\n",
       "    border: none;\n",
       "    position: relative;\n",
       "    top: 0;\n",
       "}\n",
       "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
       "    border: none;\n",
       "    background: transparent;\n",
       "    box-shadow: 0 6px 18px #aaa;\n",
       "    z-index: 10;\n",
       "    top: -10px;\n",
       "}\n",
       ".CodeMirror pre, .CodeMirror-dialog, .CodeMirror-dialog .CodeMirror-search-field, .terminal-app .terminal {\n",
       "    font-family: 'Hack' , serif; \n",
       "    font-weight: 500;\n",
       "    font-size: 14pt;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "</style>    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "<div style=\"color:#aaa;font-size:8pt\">\n",
       "<hr/>\n",
       "&copy; SupportVectors. All rights reserved. <blockquote>This notebook is the intellectual property of SupportVectors, and part of its training material. \n",
       "Only the participants in SupportVectors workshops are allowed to study the notebooks for educational purposes currently, but is prohibited from copying or using it for any other purposes without written permission.\n",
       "\n",
       "<b> These notebooks are chapters and sections from Asif Qamar's textbook that he is writing on Data Science. So we request you to not circulate the material to others.</b>\n",
       " </blockquote>\n",
       " <hr/>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run supportvectors-common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matryoshka Embeddings\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Matryoshka embeddings are an innovative approach in the field of machine learning and natural language processing, inspired by the concept of Russian nesting dolls. These embeddings are designed to prioritize and encapsulate the most significant information in the initial dimensions, allowing for efficient representation and processing of data even when truncated. This is particularly useful for capturing the hierarchical nature of natural language text, where important concepts and structures are nested within larger contexts.\n",
    "\n",
    "## Understanding Matryoshka Embeddings\n",
    "\n",
    "Matryoshka embeddings aim to store more important information in earlier dimensions, and less important information in later dimensions. This allows the embeddings to be truncated to smaller sizes without significant loss of information, making them highly efficient for various downstream tasks.\n",
    "\n",
    "### Key Characteristics:\n",
    "- **Variable Size**: Matryoshka embeddings can be truncated to different sizes, allowing for flexibility in storage and processing.\n",
    "- **Efficiency**: They enable efficient shortlisting and reranking by using smaller embeddings for initial tasks and larger ones for detailed analysis.\n",
    "\n",
    "## Applications of Matryoshka Embeddings\n",
    "\n",
    "Matryoshka embeddings are particularly useful in scenarios where data efficiency and scalability are crucial, such as:\n",
    "- **Natural Language Processing**: Enhancing tasks like nearest neighbor search and classification by using variable-size embeddings.\n",
    "- **Data Storage**: Reducing storage requirements while maintaining performance by using truncated embeddings.\n",
    "\n",
    "## Advantages of Matryoshka Embeddings\n",
    "\n",
    "- **Scalability**: They allow for scaling solutions to desired storage costs and processing speeds.\n",
    "- **Performance**: Despite truncation, they maintain high performance levels, making them suitable for a wide range of applications.\n",
    "\n",
    "## Training Matryoshka Embeddings\n",
    "\n",
    "Matryoshka embeddings are trained using a loss function that evaluates the quality of embeddings at various dimensions. This incentivizes the model to prioritize important information in the initial dimensions, ensuring that truncated embeddings remain effective.\n",
    "\n",
    "## Detailed Explanation of Loss Functions \n",
    "In the `MatryoshkaLoss` fine-tuning done at [sbert_subjects_matryoshka.py](../../src/contrastive_loss/sbert_subjects_matryoshka.py), we are using an inner contrastive loss, `CoSENTLoss`, wrapped with `MatryoshkaLoss`.\n",
    "\n",
    "### CoSENTLoss\n",
    "\n",
    "`CoSENTLoss` is one of the popular choices for contrastive loss and has already been covered in the theory as well as in the previous lab exercise.\n",
    "\n",
    "### MatryoshkaLoss\n",
    "\n",
    "`MatryoshkaLoss` is a wrapper around an inner contrastive loss (like `CoSENTLoss`). It computes a total loss by taking a weighted sum of the losses at multiple truncated dimensions.\n",
    "\n",
    "- **Multi-Dimensional Evaluation**: Unlike traditional loss functions that evaluate embeddings at a single dimension, `MatryoshkaLoss` evaluates them at multiple specified dimensions (e.g., 768, 512, 256, etc.).\n",
    "- **Weighted Loss**: Each dimension's loss can be weighted differently, allowing for flexibility in how much importance is given to each dimension. In the example, equal weights are assigned to each dimension.\n",
    "- **Hierarchical Information**: By applying the inner loss to multiple truncated dimensions, `MatryoshkaLoss` ensures that the most significant information is captured in the initial dimensions, aligning with the hierarchical nature of Matryoshka embeddings.\n",
    "\n",
    "#### Pseudocode for MatryoshkaLoss Calculation\n",
    "\n",
    "Here's a pseudocode representation of how `MatryoshkaLoss` might be calculated from a `base_loss`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_matryoshka_loss(embeddings, base_loss, matryoshka_dims, matryoshka_weight):\n",
    "    total_loss = 0\n",
    "    for i in range(len(matryoshka_dims)):\n",
    "        # Truncate the embeddings to the current dimension\n",
    "        truncated_embeddings = truncate_embeddings(embeddings, matryoshka_dims[i])\n",
    "        \n",
    "        # Calculate the base loss for the truncated embeddings\n",
    "        loss = base_loss(truncated_embeddings)\n",
    "        \n",
    "        # Weight the loss for the current dimension\n",
    "        weighted_loss = matryoshka_weight[i] * loss\n",
    "        \n",
    "        # Accumulate the weighted loss\n",
    "        total_loss += weighted_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "def truncate_embeddings(embeddings, dimension):\n",
    "    # Truncate each embedding to the specified dimension\n",
    "    return [embedding[:dimension] for embedding in embeddings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training using `SentenceTransformer` available [here](../../src/contrastive_loss/sbert_subjects_matryoshka.py)\n",
    "\n",
    "The training goal is to bring embeddings of sentences of same subject closer to each other and those of different subjects away from each other.  By bringing in Matryoshka loss, we are able to bring about this separation with embeddings even with significantly lower leading dimensions (the truncated dimensions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with Matryoshka Embeddings\n",
    "\n",
    "Once trained, Matryoshka embeddings can be used in inference just like any other embeddings. The key difference is the ability to truncate the embeddings to a desired size, which can significantly speed up downstream tasks such as retrieval and save on storage space.\n",
    "\n",
    "A base model `BAAI/bge-base-en-v1.5` was fine-tuned on a dataset of subject chunks belonging to three different subjects using `MatryoshkaLoss` here.  We now compare the inference of the base model with the fine-tuned model below to demonstrate how well the fine-tuned model continues to perform well at lower dimensions as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No configuration file specified. Trying the default location\n",
      "WARNING:root:Loading configuration from /Users/chandarl/Documents/GitHub/llm_bootcamp_curriculum/topics/contrastive_loss/config.yaml if it exists\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from contrastive_loss import config\n",
    "from contrastive_loss.sbert_subjects_matryoshka import (convert_to_pair_dataset, \n",
    "                                                       sampled_dataset, \n",
    "                                                       get_evaluator,\n",
    "                                                       get_train_test_lists,\n",
    "                                                       tuples_list_to_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device = 'cuda' if torch.cuda.is_available() else device\n",
    "# Get the base sentence transformer model\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model = SentenceTransformer(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check cosine similarities for some sample sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"The rate of change of displacement is velocity\"\n",
    "sentence2 = \"Kidney plays an important role in purifying blood\"\n",
    "sentence3 = \"Many countries obtained their freedom by 1950\"\n",
    "sentence4 = \"Force is proportional to mass\"\n",
    "sentence5 = \"Vaccines train our immune system to create antibodies\"\n",
    "sentence6 = \"World war 2 was a global conflict between two coalitions - the allies and the axis powers\"\n",
    "\n",
    "sentences = [sentence1, sentence4, sentence2, sentence5, sentence3, sentence6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6319</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4293</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4455</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4729</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4143</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6319</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4295</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4588</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4492</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4758</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4293</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4295</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5435</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3910</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3933</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4455</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4588</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5435</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3774</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3869</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4729</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4492</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3910</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3774</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5695</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4143</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4758</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3933</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3869</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5695</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1.0000\u001b[0m, \u001b[1;36m0.6319\u001b[0m, \u001b[1;36m0.4293\u001b[0m, \u001b[1;36m0.4455\u001b[0m, \u001b[1;36m0.4729\u001b[0m, \u001b[1;36m0.4143\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.6319\u001b[0m, \u001b[1;36m1.0000\u001b[0m, \u001b[1;36m0.4295\u001b[0m, \u001b[1;36m0.4588\u001b[0m, \u001b[1;36m0.4492\u001b[0m, \u001b[1;36m0.4758\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4293\u001b[0m, \u001b[1;36m0.4295\u001b[0m, \u001b[1;36m1.0000\u001b[0m, \u001b[1;36m0.5435\u001b[0m, \u001b[1;36m0.3910\u001b[0m, \u001b[1;36m0.3933\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4455\u001b[0m, \u001b[1;36m0.4588\u001b[0m, \u001b[1;36m0.5435\u001b[0m, \u001b[1;36m1.0000\u001b[0m, \u001b[1;36m0.3774\u001b[0m, \u001b[1;36m0.3869\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4729\u001b[0m, \u001b[1;36m0.4492\u001b[0m, \u001b[1;36m0.3910\u001b[0m, \u001b[1;36m0.3774\u001b[0m, \u001b[1;36m1.0000\u001b[0m, \u001b[1;36m0.5695\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4143\u001b[0m, \u001b[1;36m0.4758\u001b[0m, \u001b[1;36m0.3933\u001b[0m, \u001b[1;36m0.3869\u001b[0m, \u001b[1;36m0.5695\u001b[0m, \u001b[1;36m1.0000\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = model.encode(sentences)\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "rprint(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the evaluator to evaluate the model before and after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ad75454dbb4224be603527b7eccd7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5331 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71496128aea84517a7e2e0e9ebc92869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5331 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736a5965b834402fa677ed465ee38bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5331 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pick chunks labeled with subjects (biology, physics, history assigned to labels 0, 1, 2 respectively)\n",
    "_, test = get_train_test_lists(cfg=config)\n",
    "\n",
    "# Convert to Dataset format\n",
    "test_dataset = tuples_list_to_dataset(test)\n",
    "\n",
    "# Sample to max of 500 per label so that the paired dataset is having max of 1500*1499/2\n",
    "test_dataset = sampled_dataset(test_dataset)\n",
    "\n",
    "# Create the paired dataset consisting of (sentence1, sentence2, score) from the text/label dataset\n",
    "test_dataset = convert_to_pair_dataset(test_dataset)\n",
    "\n",
    "binary_acc_evaluator = get_evaluator(test_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7934</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_accuracy_threshold'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5591233968734741</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6735896716250351</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_f1_threshold'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5167686939239502</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6256517205422315</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.729483282674772</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_ap'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7533480569020814</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_mcc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4980760356955473</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'cosine_accuracy'\u001b[0m: \u001b[1;36m0.7934\u001b[0m,\n",
       "    \u001b[32m'cosine_accuracy_threshold'\u001b[0m: \u001b[1;36m0.5591233968734741\u001b[0m,\n",
       "    \u001b[32m'cosine_f1'\u001b[0m: \u001b[1;36m0.6735896716250351\u001b[0m,\n",
       "    \u001b[32m'cosine_f1_threshold'\u001b[0m: \u001b[1;36m0.5167686939239502\u001b[0m,\n",
       "    \u001b[32m'cosine_precision'\u001b[0m: \u001b[1;36m0.6256517205422315\u001b[0m,\n",
       "    \u001b[32m'cosine_recall'\u001b[0m: \u001b[1;36m0.729483282674772\u001b[0m,\n",
       "    \u001b[32m'cosine_ap'\u001b[0m: \u001b[1;36m0.7533480569020814\u001b[0m,\n",
       "    \u001b[32m'cosine_mcc'\u001b[0m: \u001b[1;36m0.4980760356955473\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = binary_acc_evaluator(model)\n",
    "rprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the fine-tuned Matryoshka model and repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using latest checkpoint: /Users/chandarl/results/subject-based-encoder-matryoshka/checkpoint-1500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6304</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2109</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2381</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2328</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0844</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6304</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1275</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2084</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2222</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1185</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2109</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1275</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6136</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1897</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1671</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2381</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2084</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6136</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1590</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1266</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2328</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2222</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1897</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1590</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6150</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0844</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1185</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1671</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1266</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6150</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1.0000\u001b[0m, \u001b[1;36m0.6304\u001b[0m, \u001b[1;36m0.2109\u001b[0m, \u001b[1;36m0.2381\u001b[0m, \u001b[1;36m0.2328\u001b[0m, \u001b[1;36m0.0844\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.6304\u001b[0m, \u001b[1;36m1.0000\u001b[0m, \u001b[1;36m0.1275\u001b[0m, \u001b[1;36m0.2084\u001b[0m, \u001b[1;36m0.2222\u001b[0m, \u001b[1;36m0.1185\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2109\u001b[0m, \u001b[1;36m0.1275\u001b[0m, \u001b[1;36m1.0000\u001b[0m, \u001b[1;36m0.6136\u001b[0m, \u001b[1;36m0.1897\u001b[0m, \u001b[1;36m0.1671\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2381\u001b[0m, \u001b[1;36m0.2084\u001b[0m, \u001b[1;36m0.6136\u001b[0m, \u001b[1;36m1.0000\u001b[0m, \u001b[1;36m0.1590\u001b[0m, \u001b[1;36m0.1266\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2328\u001b[0m, \u001b[1;36m0.2222\u001b[0m, \u001b[1;36m0.1897\u001b[0m, \u001b[1;36m0.1590\u001b[0m, \u001b[1;36m1.0000\u001b[0m, \u001b[1;36m0.6150\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.0844\u001b[0m, \u001b[1;36m0.1185\u001b[0m, \u001b[1;36m0.1671\u001b[0m, \u001b[1;36m0.1266\u001b[0m, \u001b[1;36m0.6150\u001b[0m, \u001b[1;36m1.0000\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "results_dir = config[\"paths\"][\"results_dir\"]\n",
    "results_sub_dir = \"subject-based-encoder-matryoshka\"\n",
    "\n",
    "# Find the latest checkpoint directory\n",
    "checkpoint_pattern = f'{results_dir}/{results_sub_dir}/checkpoint-*' \n",
    "checkpoint_dirs = glob.glob(checkpoint_pattern)\n",
    "\n",
    "# Sort by directory name (which includes the step number) and get the latest\n",
    "latest_checkpoint = sorted(checkpoint_dirs, key=lambda x: int(x.split('checkpoint-')[-1]))[-1]\n",
    "finetuned_model_dir = latest_checkpoint\n",
    "print(f\"Using latest checkpoint: {finetuned_model_dir}\")\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(finetuned_model_dir).to(device)\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "rprint(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9862</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_accuracy_threshold'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3148014545440674</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.979223125564589</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_f1_threshold'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.30114057660102844</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9701670644391408</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9884498480243161</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_ap'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9935719051116967</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_mcc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.968988216710722</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'cosine_accuracy'\u001b[0m: \u001b[1;36m0.9862\u001b[0m,\n",
       "    \u001b[32m'cosine_accuracy_threshold'\u001b[0m: \u001b[1;36m0.3148014545440674\u001b[0m,\n",
       "    \u001b[32m'cosine_f1'\u001b[0m: \u001b[1;36m0.979223125564589\u001b[0m,\n",
       "    \u001b[32m'cosine_f1_threshold'\u001b[0m: \u001b[1;36m0.30114057660102844\u001b[0m,\n",
       "    \u001b[32m'cosine_precision'\u001b[0m: \u001b[1;36m0.9701670644391408\u001b[0m,\n",
       "    \u001b[32m'cosine_recall'\u001b[0m: \u001b[1;36m0.9884498480243161\u001b[0m,\n",
       "    \u001b[32m'cosine_ap'\u001b[0m: \u001b[1;36m0.9935719051116967\u001b[0m,\n",
       "    \u001b[32m'cosine_mcc'\u001b[0m: \u001b[1;36m0.968988216710722\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = binary_acc_evaluator(model)\n",
    "rprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate with truncated dimensions\n",
    "\n",
    "This time, because of using the added Matryoshka loss terms, the sentence embeddings are trained to work well even with lower dimensions than what the original model was pre-trained for.\n",
    "\n",
    "We will try with reduced dim of 64 - this just becomes a simple configurable parameter in the below `SentenceTransformer` call.  Of course, the model should have been first trained with these additional Matryoshka loss terms and embedding dimensions.  The training of these embeddings is covered at [`sbert_subjects_matryoshka.py`](../../src/contrastive_loss/sbert_subjects_matryoshka.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m6\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6952</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1056</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1206</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1408</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2274</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6952</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1428</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0575</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0476</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1500</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1056</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1428</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6745</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0181</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0139</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1206</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0575</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6745</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0089</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0358</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1408</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0476</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0181</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0089</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7086</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2274</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0139</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0358</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7086</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m1.0000\u001b[0m,  \u001b[1;36m0.6952\u001b[0m,  \u001b[1;36m0.1056\u001b[0m,  \u001b[1;36m0.1206\u001b[0m, \u001b[1;36m-0.1408\u001b[0m, \u001b[1;36m-0.2274\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m0.6952\u001b[0m,  \u001b[1;36m1.0000\u001b[0m, \u001b[1;36m-0.1428\u001b[0m, \u001b[1;36m-0.0575\u001b[0m, \u001b[1;36m-0.0476\u001b[0m, \u001b[1;36m-0.1500\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m0.1056\u001b[0m, \u001b[1;36m-0.1428\u001b[0m,  \u001b[1;36m1.0000\u001b[0m,  \u001b[1;36m0.6745\u001b[0m,  \u001b[1;36m0.0181\u001b[0m, \u001b[1;36m-0.0139\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m0.1206\u001b[0m, \u001b[1;36m-0.0575\u001b[0m,  \u001b[1;36m0.6745\u001b[0m,  \u001b[1;36m1.0000\u001b[0m,  \u001b[1;36m0.0089\u001b[0m, \u001b[1;36m-0.0358\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.1408\u001b[0m, \u001b[1;36m-0.0476\u001b[0m,  \u001b[1;36m0.0181\u001b[0m,  \u001b[1;36m0.0089\u001b[0m,  \u001b[1;36m1.0000\u001b[0m,  \u001b[1;36m0.7086\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.2274\u001b[0m, \u001b[1;36m-0.1500\u001b[0m, \u001b[1;36m-0.0139\u001b[0m, \u001b[1;36m-0.0358\u001b[0m,  \u001b[1;36m0.7086\u001b[0m,  \u001b[1;36m1.0000\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer(finetuned_model_dir, truncate_dim=64).to(device)\n",
    "embeddings = model.encode(sentences)\n",
    "rprint(embeddings.shape)\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "rprint(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9856</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_accuracy_threshold'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2060004323720932</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9783263094521372</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_f1_threshold'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2060004323720932</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9689922480620154</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9878419452887538</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_ap'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9937554620568773</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_mcc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9676468010306561</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'cosine_accuracy'\u001b[0m: \u001b[1;36m0.9856\u001b[0m,\n",
       "    \u001b[32m'cosine_accuracy_threshold'\u001b[0m: \u001b[1;36m0.2060004323720932\u001b[0m,\n",
       "    \u001b[32m'cosine_f1'\u001b[0m: \u001b[1;36m0.9783263094521372\u001b[0m,\n",
       "    \u001b[32m'cosine_f1_threshold'\u001b[0m: \u001b[1;36m0.2060004323720932\u001b[0m,\n",
       "    \u001b[32m'cosine_precision'\u001b[0m: \u001b[1;36m0.9689922480620154\u001b[0m,\n",
       "    \u001b[32m'cosine_recall'\u001b[0m: \u001b[1;36m0.9878419452887538\u001b[0m,\n",
       "    \u001b[32m'cosine_ap'\u001b[0m: \u001b[1;36m0.9937554620568773\u001b[0m,\n",
       "    \u001b[32m'cosine_mcc'\u001b[0m: \u001b[1;36m0.9676468010306561\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = binary_acc_evaluator(model)\n",
    "rprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate at even lower dimensions (8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.986</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_accuracy_threshold'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5773349404335022</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9787363304981774</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_f1_threshold'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5773349404335022</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9781420765027322</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9793313069908814</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_ap'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.989579652371798</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_mcc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9683014322389264</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'cosine_accuracy'\u001b[0m: \u001b[1;36m0.986\u001b[0m,\n",
       "    \u001b[32m'cosine_accuracy_threshold'\u001b[0m: \u001b[1;36m0.5773349404335022\u001b[0m,\n",
       "    \u001b[32m'cosine_f1'\u001b[0m: \u001b[1;36m0.9787363304981774\u001b[0m,\n",
       "    \u001b[32m'cosine_f1_threshold'\u001b[0m: \u001b[1;36m0.5773349404335022\u001b[0m,\n",
       "    \u001b[32m'cosine_precision'\u001b[0m: \u001b[1;36m0.9781420765027322\u001b[0m,\n",
       "    \u001b[32m'cosine_recall'\u001b[0m: \u001b[1;36m0.9793313069908814\u001b[0m,\n",
       "    \u001b[32m'cosine_ap'\u001b[0m: \u001b[1;36m0.989579652371798\u001b[0m,\n",
       "    \u001b[32m'cosine_mcc'\u001b[0m: \u001b[1;36m0.9683014322389264\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer(finetuned_model_dir, truncate_dim=8).to(device)\n",
    "results = binary_acc_evaluator(model)\n",
    "rprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.987</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_accuracy_threshold'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.40127962827682495</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9803684687405617</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_f1_threshold'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.22756321728229523</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9741896758703481</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9866261398176291</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_ap'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9893803072702472</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_mcc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9706952424028501</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'cosine_accuracy'\u001b[0m: \u001b[1;36m0.987\u001b[0m,\n",
       "    \u001b[32m'cosine_accuracy_threshold'\u001b[0m: \u001b[1;36m0.40127962827682495\u001b[0m,\n",
       "    \u001b[32m'cosine_f1'\u001b[0m: \u001b[1;36m0.9803684687405617\u001b[0m,\n",
       "    \u001b[32m'cosine_f1_threshold'\u001b[0m: \u001b[1;36m0.22756321728229523\u001b[0m,\n",
       "    \u001b[32m'cosine_precision'\u001b[0m: \u001b[1;36m0.9741896758703481\u001b[0m,\n",
       "    \u001b[32m'cosine_recall'\u001b[0m: \u001b[1;36m0.9866261398176291\u001b[0m,\n",
       "    \u001b[32m'cosine_ap'\u001b[0m: \u001b[1;36m0.9893803072702472\u001b[0m,\n",
       "    \u001b[32m'cosine_mcc'\u001b[0m: \u001b[1;36m0.9706952424028501\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer(finetuned_model_dir, truncate_dim=4).to(device)\n",
    "results = binary_acc_evaluator(model)\n",
    "rprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9858</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_accuracy_threshold'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6494314670562744</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.978439113270574</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_f1_threshold'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5202029943466187</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9775485436893204</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9793313069908814</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_ap'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9838876504126947</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_mcc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9678540642553616</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'cosine_accuracy'\u001b[0m: \u001b[1;36m0.9858\u001b[0m,\n",
       "    \u001b[32m'cosine_accuracy_threshold'\u001b[0m: \u001b[1;36m0.6494314670562744\u001b[0m,\n",
       "    \u001b[32m'cosine_f1'\u001b[0m: \u001b[1;36m0.978439113270574\u001b[0m,\n",
       "    \u001b[32m'cosine_f1_threshold'\u001b[0m: \u001b[1;36m0.5202029943466187\u001b[0m,\n",
       "    \u001b[32m'cosine_precision'\u001b[0m: \u001b[1;36m0.9775485436893204\u001b[0m,\n",
       "    \u001b[32m'cosine_recall'\u001b[0m: \u001b[1;36m0.9793313069908814\u001b[0m,\n",
       "    \u001b[32m'cosine_ap'\u001b[0m: \u001b[1;36m0.9838876504126947\u001b[0m,\n",
       "    \u001b[32m'cosine_mcc'\u001b[0m: \u001b[1;36m0.9678540642553616\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer(finetuned_model_dir, truncate_dim=2).to(device)\n",
    "results = binary_acc_evaluator(model)\n",
    "rprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And finally at 1!! (of course it does not do well here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7718</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_accuracy_threshold'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7402183803457689</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_f1_threshold'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5914213013449655</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9890577507598785</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_ap'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5881248675940145</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cosine_mcc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6172055220304464</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'cosine_accuracy'\u001b[0m: \u001b[1;36m0.7718\u001b[0m,\n",
       "    \u001b[32m'cosine_accuracy_threshold'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
       "    \u001b[32m'cosine_f1'\u001b[0m: \u001b[1;36m0.7402183803457689\u001b[0m,\n",
       "    \u001b[32m'cosine_f1_threshold'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
       "    \u001b[32m'cosine_precision'\u001b[0m: \u001b[1;36m0.5914213013449655\u001b[0m,\n",
       "    \u001b[32m'cosine_recall'\u001b[0m: \u001b[1;36m0.9890577507598785\u001b[0m,\n",
       "    \u001b[32m'cosine_ap'\u001b[0m: \u001b[1;36m0.5881248675940145\u001b[0m,\n",
       "    \u001b[32m'cosine_mcc'\u001b[0m: \u001b[1;36m0.6172055220304464\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer(finetuned_model_dir, truncate_dim=1).to(device)\n",
    "results = binary_acc_evaluator(model)\n",
    "rprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key takeaway in this example is that the `f1 score` continues to be very high for all the lower dimensions all the way till 2.  Only when we go down to 1 dimension, the `f1 score` degrades significantly.  \n",
    "\n",
    "Of course this is also because in this example, the goal of the sentence encoders was only to make text of the same subject near each other and of different subjects to be away from each other.  And the total number of distinct subjects here is only three.  Hence we are able to achieve this separation even with such a low dimensionality of 2.  This will not be the case in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Matryoshka embeddings offer a powerful alternative to traditional embeddings, especially in scenarios where data efficiency and scalability are paramount. By leveraging their unique structure, they provide enhanced contextual understanding and flexibility, making them a valuable tool in the data scientist's toolkit.\n",
    "\n",
    "## References\n",
    "\n",
    "- [Matryoshka Representation Learning - Original Paper](https://arxiv.org/abs/2205.13147)\n",
    "- [Matryoshka Embeddings - Sentence Transformers Documentation](https://sbert.net/examples/sentence_transformer/training/matryoshka/README.html)\n",
    "- [MatryoshkaLoss Implementation on GitHub](https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/losses/MatryoshkaLoss.py)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
