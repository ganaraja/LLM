{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8edcfc",
   "metadata": {},
   "source": [
    "# Primer to Prompt Engineering Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01fb777",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://supportvectors.ai/logo-poster-transparent.png\" width=\"400px\" style=\"opacity:0.7\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c8907c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- Many of the styles here are inspired by: \n",
       "    https://towardsdatascience.com/10-practical-tips-you-need-to-know-to-personalize-jupyter-notebook-fbd202777e20 \n",
       "\n",
       "\n",
       "    On the author's local machine, these exist in the custom.css file. However, in order to keep uniform look and feel, \n",
       "    and at the request of participants, I have added it to this common import-file here.\n",
       "\n",
       "    -->\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Lora:400,700|Montserrat:300\" rel=\"stylesheet\">\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Crimson+Pro&family=Literata&display=swap\" rel=\"stylesheet\">\n",
       "<style>\n",
       "\n",
       "\n",
       "#ipython_notebook::before{\n",
       " content:\"Neural Architectures\";\n",
       "        color: white;\n",
       "        font-weight: bold;\n",
       "        text-transform: uppercase;\n",
       "        font-family: 'Lora',serif;\n",
       "        font-size:16pt;\n",
       "        margin-bottom:15px;\n",
       "        margin-top:15px;\n",
       "\n",
       "}\n",
       "body > #header {\n",
       "    #background: #D15555;\n",
       "    background: linear-gradient(to bottom, indianred 0%, #fff 100%);\n",
       "    opacity: 0.8;\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       ".navbar-default .navbar-nav > li > a, #kernel_indicator {\n",
       "    color: white;\n",
       "    transition: all 0.25s;\n",
       "    font-size:10pt;\n",
       "    font-family: sans-serif;\n",
       "    font-weight:normal;\n",
       "}\n",
       ".navbar-default {\n",
       "    padding-left:100px;\n",
       "    background: none;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       "\n",
       "body > menubar-container {\n",
       "    background-color: wheat;\n",
       "}\n",
       "#ipython_notebook img{                                                                                        \n",
       "    display:block; \n",
       "\n",
       "    background: url(\"https://www.supportvectors.com/wp-content/uploads/2016/03/logo-poster-smaller.png\") no-repeat;\n",
       "    background-size: contain;\n",
       "\n",
       "    padding-left: 600px;\n",
       "    padding-right: 100px;\n",
       "\n",
       "    -moz-box-sizing: border-box;\n",
       "    box-sizing: border-box;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "body {\n",
       " #font-family:  'Literata', serif;\n",
       "    font-family:'Lora', san-serif;\n",
       "    text-align: justify;\n",
       "    font-weight: 400;\n",
       "    font-size: 12pt;\n",
       "}\n",
       "\n",
       "iframe{\n",
       "    width:100%;\n",
       "    min-height:600px;\n",
       "}\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "# font-family: 'Montserrat', sans-serif;\n",
       " font-family:'Lora', serif;\n",
       " font-weight: 200;\n",
       " text-transform: uppercase;\n",
       " color: #EC7063 ;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "    color: #000080;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       "#notebook_name {\n",
       "    font-weight: 600;\n",
       "    font-size:20pt;\n",
       "    text-variant:uppercase;\n",
       "    color: wheat; \n",
       "    margin-right:20px;\n",
       "    margin-left:-500px;\n",
       "}\n",
       "#notebook_name:hover {\n",
       "background-color: salmon;\n",
       "}\n",
       "\n",
       "\n",
       ".dataframe { /* dataframe atau table */\n",
       "    background: white;\n",
       "    box-shadow: 0px 1px 2px #bbb;\n",
       "}\n",
       ".dataframe thead th, .dataframe tbody td {\n",
       "    text-align: center;\n",
       "    padding: 1em;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       ".output {\n",
       "    align-items: center;\n",
       "}\n",
       "\n",
       "div.cell {\n",
       "    transition: all 0.25s;\n",
       "    border: none;\n",
       "    position: relative;\n",
       "    top: 0;\n",
       "}\n",
       "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
       "    border: none;\n",
       "    background: transparent;\n",
       "    box-shadow: 0 6px 18px #aaa;\n",
       "    z-index: 10;\n",
       "    top: -10px;\n",
       "}\n",
       ".CodeMirror pre, .CodeMirror-dialog, .CodeMirror-dialog .CodeMirror-search-field, .terminal-app .terminal {\n",
       "    font-family: 'Hack' , serif; \n",
       "    font-weight: 500;\n",
       "    font-size: 14pt;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "</style>    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "<div style=\"color:#aaa;font-size:8pt\">\n",
       "<hr/>\n",
       "&copy; SupportVectors. All rights reserved. <blockquote>This notebook is the intellectual property of SupportVectors, and part of its training material. \n",
       "Only the participants in SupportVectors workshops are allowed to study the notebooks for educational purposes currently, but is prohibited from copying or using it for any other purposes without written permission.\n",
       "\n",
       "<b> These notebooks are chapters and sections from Asif Qamar's textbook that he is writing on Data Science. So we request you to not circulate the material to others.</b>\n",
       " </blockquote>\n",
       " <hr/>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run supportvectors-common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea22281",
   "metadata": {},
   "source": [
    "## LLM Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58093a30",
   "metadata": {},
   "source": [
    "- **Temperature**\n",
    "  - Controls randomness of output.\n",
    "  - **Low (e.g., 0.2)** → deterministic, factual.\n",
    "  - **High (e.g., 0.8)** → creative, varied.\n",
    "  - Best for creative tasks when high; factual tasks when low.\n",
    "\n",
    "- **Top P (Nucleus Sampling)**\n",
    "  - Limits selection to top tokens making up `p` probability mass.\n",
    "  - **Low (e.g., 0.2)** → focused, confident answers.\n",
    "  - **High (e.g., 0.9)** → broader, more diverse responses.\n",
    "  - **Use either Temperature *or* Top P, not both.**\n",
    "\n",
    "- **Max Length**\n",
    "  - Sets the limit for generated tokens.\n",
    "  - Controls verbosity, relevance, and cost.\n",
    "\n",
    "- **Stop Sequences**\n",
    "  - Defines strings that stop further generation.\n",
    "  - Useful for structured output control (e.g., `\"11\"` to end a 10-item list).\n",
    "\n",
    "- **Frequency Penalty**\n",
    "  - Penalizes tokens based on **how often** they’ve appeared.\n",
    "  - Higher value reduces **word repetition**.\n",
    "\n",
    "- **Presence Penalty**\n",
    "  - Penalizes if a token **has appeared before**, regardless of frequency.\n",
    "  - Higher value encourages **topic diversity**; lower keeps model focused."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f100c3c",
   "metadata": {},
   "source": [
    "## Chat App vs. API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ab3e6c",
   "metadata": {},
   "source": [
    "| Feature                     | Chat Application                            | API Usage                                           |\n",
    "|----------------------------|---------------------------------------------|-----------------------------------------------------|\n",
    "| **Prompt Format & Roles**  | Free-form input; implicit system behavior   | Structured messages with `system`, `user`, `assistant` |\n",
    "| **Context Handling**       | Handled automatically                       | Requires full message history per request           |\n",
    "| **Parameter Control**      | Limited or preset (e.g., sliders)           | Full access to `temperature`, `top_p`, etc.         |\n",
    "| **Behavior Control**       | Basic tone/style via UI                     | Fine-tuned via system prompts and parameters         |\n",
    "| **Workflow Automation**    | Manual only                                 | Scriptable pipelines, agents, batch jobs            |\n",
    "| **Tool Integration**       | Limited to plugins or UI extensions         | Full function/tool calling and external tool use     |\n",
    "| **Prompt Flexibility**     | Manual edits only                           | Dynamic prompts, templating, A/B testing             |\n",
    "| **Output Control**         | Length managed internally                   | Customizable via `max_tokens`, `stop`, etc.          |\n",
    "| **Streaming**              | Rare or limited                             | Fully supported (`stream=True`)                     |\n",
    "| **Logging & Debugging**    | No access to usage data                     | Token usage, latency, cost details available         |\n",
    "| **Provider Differences**   | Abstracted away                             | Must handle provider-specific formats                |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f88832e",
   "metadata": {},
   "source": [
    "## Fundamentals of Prompting with LLM APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c571f7",
   "metadata": {},
   "source": [
    "**The Core Concept: Message-Based Prompting**\n",
    "\n",
    "At its core, prompting via API is about constructing a sequence of messages exchanged between a user and a model, optionally guided by a system instruction.\n",
    "\n",
    "These messages form a dialogue — even for single-shot tasks.\n",
    "\n",
    "Canonical Roles:\n",
    "- system: sets behavior, tone, or constraints\n",
    "- user: provides tasks, questions, or instructions\n",
    "- assistant: stores previous responses (optional for history)\n",
    "- (some APIs also support tools, function calls, or tool outputs)\n",
    "\n",
    "**The Minimal Request Structure**\n",
    "\n",
    "Every API interaction contains:\n",
    "- A list of messages, usually as [ { role, content }, ... ]\n",
    "- Model parameters, like temperature, top_p, max_tokens\n",
    "- Optional settings like stop sequences, tool definitions, etc.\n",
    "\n",
    "Example abstract structure:\n",
    "```\n",
    "{\n",
    "  \"model\": \"<model-name>\",\n",
    "  \"messages\": [\n",
    "    { \"role\": \"system\", \"content\": \"You are a helpful assistant.\" },\n",
    "    { \"role\": \"user\", \"content\": \"What's the capital of France?\" }\n",
    "  ],\n",
    "  \"temperature\": 0.7,\n",
    "  \"top_p\": 1.0,\n",
    "  \"max_tokens\": 100,\n",
    "  \"stop\": [\"User:\"]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fd36de",
   "metadata": {},
   "source": [
    "**The Three Layers of Prompt Design**\n",
    "\n",
    "a. Instruction Layer\n",
    "    - Set expectations and behavior via system prompt or context.\n",
    "\n",
    "b. Input Layer\n",
    "    - Define user intent clearly — question, task, or data.\n",
    "\n",
    "c. Output Framing Layer\n",
    "    - Use examples, formatting hints, stop tokens, or few-shot samples to guide structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f40647",
   "metadata": {},
   "source": [
    "**Prompting is Functional Programming with Language**\n",
    "- Each prompt is a pure function:\n",
    "\n",
    "    ```output = LLM(prompt, params)```\n",
    "\n",
    "- Context (messages) is your program state\n",
    "- Parameters (temperature, etc.) are tuning knobs\n",
    "- You can compose, refactor, debug, and version prompts like code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935655b9",
   "metadata": {},
   "source": [
    "## OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9a9ee3",
   "metadata": {},
   "source": [
    "This introduces the core concepts behind the OpenAI API so you can start using it effectively for prompting, automation, and app development.\n",
    "\n",
    "### What is the OpenAI API?\n",
    "\n",
    "The OpenAI API allows developers to interact with language models like **GPT-4**, **GPT-3.5**, and **embedding models** via HTTPS requests. You send a structured request (usually JSON), and receive a generated response.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "#### a. Endpoints\n",
    "\n",
    "The main ones you’ll use:\n",
    "\n",
    "| Endpoint           | Purpose                              |\n",
    "|--------------------|--------------------------------------|\n",
    "| `/v1/chat/completions` | Chat-based interaction with GPT-4 / GPT-3.5 |\n",
    "| `/v1/completions`      | Legacy prompt-completion format   |\n",
    "| `/v1/embeddings`       | Convert text into vector embeddings |\n",
    "\n",
    "\n",
    "#### b. Message Structure\n",
    "\n",
    "The chat endpoint uses a **message-based format**:\n",
    "\n",
    "```json\n",
    "  [\n",
    "    { \"role\": \"system\", \"content\": \"You are a helpful assistant.\" },\n",
    "    { \"role\": \"user\", \"content\": \"Explain quantum computing in simple terms.\" }\n",
    "  ]\n",
    "```\n",
    "##### A minimal `python` example calling the `OpenAI` API:\n",
    "```python\n",
    "from openai import OpenAI\n",
    "api = OpenAI()\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "  {\"role\": \"user\", \"content\": \"Explain quantum computing in simple terms.\"}\n",
    "  ]\n",
    "response = api.chat.completions.create(model=\"gpt-4o\", messages = messages)\n",
    "```\n",
    "\n",
    "**Roles** :\n",
    "- system: Sets the model’s behavior or persona\n",
    "- user: Represents the user’s input\n",
    "- assistant: (Optional) previous model responses for context\n",
    "\n",
    "**Parameters**:\n",
    "- temperature\n",
    "- top_p\n",
    "- max_tokens\n",
    "- stop\n",
    "- stream\n",
    "\n",
    "**API Key**\n",
    "You need an API key from https://platform.openai.com/account/api-keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863950cf",
   "metadata": {},
   "source": [
    "## Instructor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c45f0b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Instructor** is a lightweight Python library that helps you get **structured, typed, and validated outputs** from language models like OpenAI’s GPT or Anthropic’s Claude.\n",
    "\n",
    "It works by combining:\n",
    "- **LLMs (OpenAI, Claude, etc.)**\n",
    "- **Pydantic** for defining strict data schemas\n",
    "- A single function call to generate **safe, parseable** outputs\n",
    "\n",
    "### Why Use Instructor?\n",
    "\n",
    "LLMs are great at generating natural language, but:\n",
    "- Their output is **unpredictable**\n",
    "- You often need **structured formats** (JSON, dicts, typed objects)\n",
    "- Manual parsing is error-prone\n",
    "\n",
    "**Instructor solves this** by:\n",
    "- Letting you define expected outputs as Python classes\n",
    "- Handling prompting and validation under the hood\n",
    "- Failing gracefully if the model output doesn't match the schema\n",
    "\n",
    "```python\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "client = instructor.from_openai(OpenAI())\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "user_prompt = \"Give me a person named Alice who is 30 years old\"\n",
    "result = self.api.chat.completions.create(model=\"gpt-4o\", \n",
    "                                            messages=[\n",
    "                                                        {\"role\": \"user\", \"content\": user_prompt}\n",
    "                                                        ],\n",
    "                                            response_model=Person,\n",
    "                                            )\n",
    "print(result.name)  # Alice\n",
    "print(result.age)   # 30\n",
    "```\n",
    "\n",
    "**Supported LLMs**\n",
    "- OpenAI (GPT-3.5, GPT-4, GPT-4o)\n",
    "- Claude 3 (via Anthropic client)\n",
    "- Mistral (via Together.ai, HuggingFace, etc.)\n",
    "- Custom models (with plugin adapters)\n",
    "\n",
    "**Use Cases**\n",
    "- Extract structured data from unstructured text\n",
    "- Turn user input into form-ready objects\n",
    "- Power agents with typed memory/state\n",
    "- Safe JSON generation from LLMs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca36c448",
   "metadata": {},
   "source": [
    "## Libraries and Frameworks Used\n",
    "\n",
    "#### **Core Dependencies:**\n",
    "- **OpenAI** (`openai`) - OpenAI API client for GPT models\n",
    "- **Instructor** (`instructor`) - Structured output framework for LLMs\n",
    "- **Pydantic** (`pydantic`) - Data validation and model definition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
