{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM API Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://supportvectors.ai/logo-poster-transparent.png\" width=\"400px\" style=\"opacity:0.7\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- Many of the styles here are inspired by: \n",
       "    https://towardsdatascience.com/10-practical-tips-you-need-to-know-to-personalize-jupyter-notebook-fbd202777e20 \n",
       "\n",
       "\n",
       "    On the author's local machine, these exist in the custom.css file. However, in order to keep uniform look and feel, \n",
       "    and at the request of participants, I have added it to this common import-file here.\n",
       "\n",
       "    -->\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Lora:400,700|Montserrat:300\" rel=\"stylesheet\">\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Crimson+Pro&family=Literata&display=swap\" rel=\"stylesheet\">\n",
       "<style>\n",
       "\n",
       "\n",
       "#ipython_notebook::before{\n",
       " content:\"Neural Architectures\";\n",
       "        color: white;\n",
       "        font-weight: bold;\n",
       "        text-transform: uppercase;\n",
       "        font-family: 'Lora',serif;\n",
       "        font-size:16pt;\n",
       "        margin-bottom:15px;\n",
       "        margin-top:15px;\n",
       "\n",
       "}\n",
       "body > #header {\n",
       "    #background: #D15555;\n",
       "    background: linear-gradient(to bottom, indianred 0%, #fff 100%);\n",
       "    opacity: 0.8;\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       ".navbar-default .navbar-nav > li > a, #kernel_indicator {\n",
       "    color: white;\n",
       "    transition: all 0.25s;\n",
       "    font-size:10pt;\n",
       "    font-family: sans-serif;\n",
       "    font-weight:normal;\n",
       "}\n",
       ".navbar-default {\n",
       "    padding-left:100px;\n",
       "    background: none;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       "\n",
       "body > menubar-container {\n",
       "    background-color: wheat;\n",
       "}\n",
       "#ipython_notebook img{                                                                                        \n",
       "    display:block; \n",
       "\n",
       "    background: url(\"https://www.supportvectors.com/wp-content/uploads/2016/03/logo-poster-smaller.png\") no-repeat;\n",
       "    background-size: contain;\n",
       "\n",
       "    padding-left: 600px;\n",
       "    padding-right: 100px;\n",
       "\n",
       "    -moz-box-sizing: border-box;\n",
       "    box-sizing: border-box;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "body {\n",
       " #font-family:  'Literata', serif;\n",
       "    font-family:'Lora', san-serif;\n",
       "    text-align: justify;\n",
       "    font-weight: 400;\n",
       "    font-size: 12pt;\n",
       "}\n",
       "\n",
       "iframe{\n",
       "    width:100%;\n",
       "    min-height:600px;\n",
       "}\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "# font-family: 'Montserrat', sans-serif;\n",
       " font-family:'Lora', serif;\n",
       " font-weight: 200;\n",
       " text-transform: uppercase;\n",
       " color: #EC7063 ;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "    color: #000080;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       "#notebook_name {\n",
       "    font-weight: 600;\n",
       "    font-size:20pt;\n",
       "    text-variant:uppercase;\n",
       "    color: wheat; \n",
       "    margin-right:20px;\n",
       "    margin-left:-500px;\n",
       "}\n",
       "#notebook_name:hover {\n",
       "background-color: salmon;\n",
       "}\n",
       "\n",
       "\n",
       ".dataframe { /* dataframe atau table */\n",
       "    background: white;\n",
       "    box-shadow: 0px 1px 2px #bbb;\n",
       "}\n",
       ".dataframe thead th, .dataframe tbody td {\n",
       "    text-align: center;\n",
       "    padding: 1em;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       ".output {\n",
       "    align-items: center;\n",
       "}\n",
       "\n",
       "div.cell {\n",
       "    transition: all 0.25s;\n",
       "    border: none;\n",
       "    position: relative;\n",
       "    top: 0;\n",
       "}\n",
       "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
       "    border: none;\n",
       "    background: transparent;\n",
       "    box-shadow: 0 6px 18px #aaa;\n",
       "    z-index: 10;\n",
       "    top: -10px;\n",
       "}\n",
       ".CodeMirror pre, .CodeMirror-dialog, .CodeMirror-dialog .CodeMirror-search-field, .terminal-app .terminal {\n",
       "    font-family: 'Hack' , serif; \n",
       "    font-weight: 500;\n",
       "    font-size: 14pt;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "</style>    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "<div style=\"color:#aaa;font-size:8pt\">\n",
       "<hr/>\n",
       "&copy; SupportVectors. All rights reserved. <blockquote>This notebook is the intellectual property of SupportVectors, and part of its training material. \n",
       "Only the participants in SupportVectors workshops are allowed to study the notebooks for educational purposes currently, but is prohibited from copying or using it for any other purposes without written permission.\n",
       "\n",
       "<b> These notebooks are chapters and sections from Asif Qamar's textbook that he is writing on Data Science. So we request you to not circulate the material to others.</b>\n",
       " </blockquote>\n",
       " <hr/>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run supportvectors-common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ollama Installation Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run ollama using instructions from [here](https://github.com/ollama/ollama).  \n",
    "\n",
    "The Linux instructions alone reproduced below.  Check for Mac or Windows from above link\n",
    "\n",
    "1. `curl -fsSL https://ollama.com/install.sh | sh` (to install ollama)\n",
    "2. `ollama pull llama3.2` to pull `llama3.2` model.\n",
    "3. `ollama run llama3.2` (to run `ollama` on the command line with `llama3.2` model)\n",
    "4. To access `llama3.2` model on `ollama` through a REST API:\n",
    "    ```\n",
    "    curl http://localhost:11434/api/generate -d '{\n",
    "    \"model\": \"llama3.2\",\n",
    "    \"prompt\":\"Why is the sky blue?\"\n",
    "    }'\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have `ollama` running as above, accessing models through a REST API can be done very similarly to how one accesses OpenAI through an API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from rich import print as rprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing LLMs served by ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ollama serves models on port 11434.  The model being served can be specified during the api call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "\n",
    "    # required but ignored\n",
    "    api_key='ollama',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "llama3.2 is being served in the below call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-462'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Accessing OpenAI through a REST API involves several steps:\\n\\n**Prerequisites:**\\n\\n1. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Create an account on OpenAI\\'s website (&lt;https://api.openai.com/&gt;) and obtain an API key.\\n2. Make sure you have a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">stable internet connection.\\n\\n**Instructions to access OpenAI through a REST API:**\\n\\n### Step 1: Identify the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">desired API endpoint\\n\\nOpenAI offers several APIs, including:\\n\\n* **ChatGPT:** For conversational AI\\n* </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">**Text-to-Speech (TTS):** For text-to-speech conversion\\n* **Image Generation:** For generating images\\n* **API </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">limits:** For general-purpose NLP tasks\\n\\nChoose the relevant API and endpoint based on your use case.\\n\\n### Step</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2: Use the OpenAI Console or command-line arguments to fetch access tokens\\n\\nYou can either obtain an access token</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">directly from the OpenAI website using the console (1) or fetch it programmatically by sending a GET request with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">your API key:\\n\\n#### Using OpenAI Console:\\n```bash\\ncurl \\'https://api.openai.com/v1/access-token\\' -X GET \\\\\\n  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">-H \\'Content-Type: application/json\\' \\\\\\n  -H \\'Authorization: Bearer YOUR_API_KEY\\' \\\\\\n```\\n\\nReplace </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">`YOUR_API_KEY` with the actual API key provided during sign-up.\\n\\n#### Using Python or command-line arguments </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(recommended):\\n```bash\\npython -m requests.get(\\'https://api.openai.com/v1/access-token\\', </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">headers={\\'Authorization\\': f\\'Bearer {YOUR_API_KEY}\\'})\\n```\\nThis will output the access token.\\n\\n### Step 3: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Get an instance and execute a request\\n\\nYou can now use the obtained access token to get an instance of the API </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">client:\\n```python\\nimport requests\\nfrom openai.api ai_client import AiClient\\n\\n# Initialize the AI client with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">your access token\\nclient = AiClient(access_token=YOUR_ACCESS_TOKEN)\\n\\n# Use the instance to create a completion </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">object for ChatGPT\\ncompletion = client.completion.create(\\n    prompt=\\'Write a short poem\\',\\n    </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">max_tokens=1024,\\n    top_k=60\\n)\\n```\\nThe example uses Python; you can adapt this process using any programming </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language or framework that allows HTTP requests.\\n\\n### Step 4: Follow the request\\'s response\\n\\nRead and analyze </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the response object generated by OpenAI. This will typically contain a JSON-formatted structure containing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information related to your query (e.g., answer text, metadata).\\n\\nHere is an example of how to parse </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">this:\\n```python\\nprint(completion)\\n```\\nThis would output:\\n```json\\n{\\n  \"id\": \"&lt;ID&gt;\", \"results\": [\\n    {\\n    </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"result_id\": \"&lt;RESULT_ID&gt;\",\\n      \"score\": &lt;SCORE&gt;,\\n      \"token_ids\": [ \"&lt;token IDs&gt;\", \"...\"],\\n      </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"next_token\": &lt;NEXT_TOKEN&gt;,\\n    }\\n  ]\\n}\\n```\\nNote: Response formats might vary depending on the API </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">endpoint.\\n\\n### Additional considerations:\\n\\n* Be aware of **request limits**: OpenAI API rates requests per user</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and time frame to prevent abuse.\\n* Respect usage policies, such as limiting responses per day or request </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">frequency, according to documentation for your chosen API endpoint.\\n* Familiarize yourself with error responses: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">API errors can vary depending on the use case.'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1758687568</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'llama3.2'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_ollama'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">664</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">701</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-462'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'Accessing OpenAI through a REST API involves several steps:\\n\\n**Prerequisites:**\\n\\n1. \u001b[0m\n",
       "\u001b[32mCreate an account on OpenAI\\'s website \u001b[0m\u001b[32m(\u001b[0m\u001b[32m<\u001b[0m\u001b[32mhttps:\u001b[0m\u001b[32m//api.openai.com/>\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and obtain an API key.\\n2. Make sure you have a \u001b[0m\n",
       "\u001b[32mstable internet connection.\\n\\n**Instructions to access OpenAI through a REST API:**\\n\\n### Step 1: Identify the \u001b[0m\n",
       "\u001b[32mdesired API endpoint\\n\\nOpenAI offers several APIs, including:\\n\\n* **ChatGPT:** For conversational AI\\n* \u001b[0m\n",
       "\u001b[32m**Text-to-Speech \u001b[0m\u001b[32m(\u001b[0m\u001b[32mTTS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:** For text-to-speech conversion\\n* **Image Generation:** For generating images\\n* **API \u001b[0m\n",
       "\u001b[32mlimits:** For general-purpose NLP tasks\\n\\nChoose the relevant API and endpoint based on your use case.\\n\\n### Step\u001b[0m\n",
       "\u001b[32m2: Use the OpenAI Console or command-line arguments to fetch access tokens\\n\\nYou can either obtain an access token\u001b[0m\n",
       "\u001b[32mdirectly from the OpenAI website using the console \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or fetch it programmatically by sending a GET request with \u001b[0m\n",
       "\u001b[32myour API key:\\n\\n#### Using OpenAI Console:\\n```bash\\ncurl \\'https://api.openai.com/v1/access-token\\' -X GET \\\\\\n  \u001b[0m\n",
       "\u001b[32m-H \\'Content-Type: application/json\\' \\\\\\n  -H \\'Authorization: Bearer YOUR_API_KEY\\' \\\\\\n```\\n\\nReplace \u001b[0m\n",
       "\u001b[32m`YOUR_API_KEY` with the actual API key provided during sign-up.\\n\\n#### Using Python or command-line arguments \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mrecommended\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n```bash\\npython -m requests.get\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\'https://api.openai.com/v1/access-token\\', \u001b[0m\n",
       "\u001b[32mheaders\u001b[0m\u001b[32m=\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'Authorization\\': f\\'Bearer \u001b[0m\u001b[32m{\u001b[0m\u001b[32mYOUR_API_KEY\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n```\\nThis will output the access token.\\n\\n### Step 3: \u001b[0m\n",
       "\u001b[32mGet an instance and execute a request\\n\\nYou can now use the obtained access token to get an instance of the API \u001b[0m\n",
       "\u001b[32mclient:\\n```python\\nimport requests\\nfrom openai.api ai_client import AiClient\\n\\n# Initialize the AI client with \u001b[0m\n",
       "\u001b[32myour access token\\nclient = AiClient\u001b[0m\u001b[32m(\u001b[0m\u001b[32maccess_token\u001b[0m\u001b[32m=\u001b[0m\u001b[32mYOUR_ACCESS_TOKEN\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n# Use the instance to create a completion \u001b[0m\n",
       "\u001b[32mobject for ChatGPT\\ncompletion = client.completion.create\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\n    \u001b[0m\u001b[32mprompt\u001b[0m\u001b[32m=\\'Write a short poem\\',\\n    \u001b[0m\n",
       "\u001b[32mmax_tokens\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1024\u001b[0m\u001b[32m,\\n    \u001b[0m\u001b[32mtop_k\u001b[0m\u001b[32m=\u001b[0m\u001b[32m60\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n```\\nThe example uses Python; you can adapt this process using any programming \u001b[0m\n",
       "\u001b[32mlanguage or framework that allows HTTP requests.\\n\\n### Step 4: Follow the request\\'s response\\n\\nRead and analyze \u001b[0m\n",
       "\u001b[32mthe response object generated by OpenAI. This will typically contain a JSON-formatted structure containing \u001b[0m\n",
       "\u001b[32minformation related to your query \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., answer text, metadata\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\\nHere is an example of how to parse \u001b[0m\n",
       "\u001b[32mthis:\\n```python\\nprint\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcompletion\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n```\\nThis would output:\\n```json\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n  \"id\": \"<ID>\", \"results\": \u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\n    \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \u001b[0m\n",
       "\u001b[32m\"result_id\": \"<RESULT_ID>\",\\n      \"score\": <SCORE>,\\n      \"token_ids\": \u001b[0m\u001b[32m[\u001b[0m\u001b[32m \"<token IDs>\", \"...\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\\n      \u001b[0m\n",
       "\u001b[32m\"next_token\": <NEXT_TOKEN\u001b[0m\u001b[32m>\u001b[0m\u001b[32m,\\n    \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n  \u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n```\\nNote: Response formats might vary depending on the API \u001b[0m\n",
       "\u001b[32mendpoint.\\n\\n### Additional considerations:\\n\\n* Be aware of **request limits**: OpenAI API rates requests per user\u001b[0m\n",
       "\u001b[32mand time frame to prevent abuse.\\n* Respect usage policies, such as limiting responses per day or request \u001b[0m\n",
       "\u001b[32mfrequency, according to documentation for your chosen API endpoint.\\n* Familiarize yourself with error responses: \u001b[0m\n",
       "\u001b[32mAPI errors can vary depending on the use case.'\u001b[0m,\n",
       "                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33mannotations\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1758687568\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'llama3.2'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_ollama'\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m664\u001b[0m,\n",
       "        \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m37\u001b[0m,\n",
       "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m701\u001b[0m,\n",
       "        \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'What are the instructions to access openAI through a REST API',\n",
    "        }\n",
    "    ],\n",
    "    model='llama3.2',\n",
    ")\n",
    "rprint(chat_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Completion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cmpl-548'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionChoice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"To access OpenAI through a REST API, you'll need to create an account on the OpenAI platform and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">obtain an API key. Here's a step-by-step guide:\\n\\n**Prerequisites:**\\n\\n1. Create an account on OpenAI: Go to the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">[OpenAI website](https://beta.openai.com/) and sign up for an account.\\n2. Enable the API: After creating your </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">account, navigate to the [OpenAI dashboard](https://beta.openai.com/api) and enable the API.\\n3. Obtain an API key:</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Once you've enabled the API, generate a new API key.\\n\\n**Using the OpenAI REST API**\\n\\nTo use the OpenAI REST </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">API, you can follow these instructions:\\n\\n### 1. Install the `requests` library\\n\\nYou'll need to install the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">`requests` library to send HTTP requests to the OpenAI API. You can do this using pip:\\n```bash\\npip install </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">requests\\n```\\n### 2. Set up authentication\\n\\nTo access the OpenAI API, you'll need to set up authentication using</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">an API key or a token. You can use either method:\\n\\n#### Using an API Key\\nCreate a dictionary with your API key </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and store it in a variable:\\n```python\\napi_key = 'your_openai_api_key_here'\\n```\\n#### Using an API Token\\nYou can</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">obtain an API token from the OpenAI dashboard, which will have the same functionality as an API key.\\n\\nSend a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">request with the API key or token:\\n```python\\nimport requests\\n\\nheaders = {'Authorization': f'Bearer </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{api_key}'}\\nresponse = requests.get('https://api.openai.com/v1/objects', headers=headers)\\n```\\n### 3. Send a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">request to the OpenAI API\\n\\nUse your favorite HTTP library (e.g., `requests`) to send a GET request to any of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">following endpoints:\\n\\n* **Text analysis:** [https://api.openai.com/v1/text](https://api.openai.com/v1/text)\\n* </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">**Image analysis:** [https://api.openai.com/v1/image](https://api.openai.com/v1/image)\\n* **Chatbot API:** </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">[https://api.openai.com/v1/chat](https://api.openai.com/v1/chat)\\n\\nExample request:\\n```python\\nimport </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">requests\\n\\nheaders = {'Authorization': 'Bearer your_openai_api_key_here'}\\ntext_data = {\\n    'prompt': 'Write a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">short story about a character who discovers a hidden world.',\\n    'max_tokens': 200,\\n    'top_k': </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">50,\\n}\\n\\nresponse = requests.post('https://api.openai.com/v1/text', json=text_data, headers=headers)\\n```\\n### 4. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Parse the response\\n\\nThe API will return a JSON object with results. You can parse this response using Python's </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">built-in `json` library or another parsing library like `xml.etree.ElementTree`.\\n\\nExample:\\n```python\\nimport </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">json\\n\\nresponse_json = json.loads(response.text)\\nprint(response_json['object'])\\n```\\n### Notes:\\n\\n* The OpenAI </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">API has usage limits, and the free tier can be used for up to 50 calls per month.\\n* Some features of the API may </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">require a paid subscription or additional authentication.\\n* Be mindful of OpenAI's terms of service and usage </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">guidelines when using their API in production.\"</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1758620686</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'llama3.2'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text_completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_ollama'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">677</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">714</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'cmpl-548'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mCompletionChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtext\u001b[0m=\u001b[32m\"To\u001b[0m\u001b[32m access OpenAI through a REST API, you'll need to create an account on the OpenAI platform and \u001b[0m\n",
       "\u001b[32mobtain an API key. Here's a step-by-step guide:\\n\\n**Prerequisites:**\\n\\n1. Create an account on OpenAI: Go to the \u001b[0m\n",
       "\u001b[32m[\u001b[0m\u001b[32mOpenAI website\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://beta.openai.com/\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and sign up for an account.\\n2. Enable the API: After creating your \u001b[0m\n",
       "\u001b[32maccount, navigate to the \u001b[0m\u001b[32m[\u001b[0m\u001b[32mOpenAI dashboard\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://beta.openai.com/api\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and enable the API.\\n3. Obtain an API key:\u001b[0m\n",
       "\u001b[32mOnce you've enabled the API, generate a new API key.\\n\\n**Using the OpenAI REST API**\\n\\nTo use the OpenAI REST \u001b[0m\n",
       "\u001b[32mAPI, you can follow these instructions:\\n\\n### 1. Install the `requests` library\\n\\nYou'll need to install the \u001b[0m\n",
       "\u001b[32m`requests` library to send HTTP requests to the OpenAI API. You can do this using pip:\\n```bash\\npip install \u001b[0m\n",
       "\u001b[32mrequests\\n```\\n### 2. Set up authentication\\n\\nTo access the OpenAI API, you'll need to set up authentication using\u001b[0m\n",
       "\u001b[32man API key or a token. You can use either method:\\n\\n#### Using an API Key\\nCreate a dictionary with your API key \u001b[0m\n",
       "\u001b[32mand store it in a variable:\\n```python\\napi_key = 'your_openai_api_key_here'\\n```\\n#### Using an API Token\\nYou can\u001b[0m\n",
       "\u001b[32mobtain an API token from the OpenAI dashboard, which will have the same functionality as an API key.\\n\\nSend a \u001b[0m\n",
       "\u001b[32mrequest with the API key or token:\\n```python\\nimport requests\\n\\nheaders = \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'Authorization': f'Bearer \u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32mapi_key\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\nresponse = requests.get\u001b[0m\u001b[32m(\u001b[0m\u001b[32m'https://api.openai.com/v1/objects', \u001b[0m\u001b[32mheaders\u001b[0m\u001b[32m=\u001b[0m\u001b[32mheaders\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n```\\n### 3. Send a \u001b[0m\n",
       "\u001b[32mrequest to the OpenAI API\\n\\nUse your favorite HTTP library \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., `requests`\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to send a GET request to any of the \u001b[0m\n",
       "\u001b[32mfollowing endpoints:\\n\\n* **Text analysis:** \u001b[0m\u001b[32m[\u001b[0m\u001b[32mhttps://api.openai.com/v1/text\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://api.openai.com/v1/text\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n* \u001b[0m\n",
       "\u001b[32m**Image analysis:** \u001b[0m\u001b[32m[\u001b[0m\u001b[32mhttps://api.openai.com/v1/image\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://api.openai.com/v1/image\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n* **Chatbot API:** \u001b[0m\n",
       "\u001b[32m[\u001b[0m\u001b[32mhttps://api.openai.com/v1/chat\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://api.openai.com/v1/chat\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\nExample request:\\n```python\\nimport \u001b[0m\n",
       "\u001b[32mrequests\\n\\nheaders = \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'Authorization': 'Bearer your_openai_api_key_here'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\ntext_data = \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    'prompt': 'Write a \u001b[0m\n",
       "\u001b[32mshort story about a character who discovers a hidden world.',\\n    'max_tokens': 200,\\n    'top_k': \u001b[0m\n",
       "\u001b[32m50,\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nresponse = requests.post\u001b[0m\u001b[32m(\u001b[0m\u001b[32m'https://api.openai.com/v1/text', \u001b[0m\u001b[32mjson\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtext_data\u001b[0m\u001b[32m, \u001b[0m\u001b[32mheaders\u001b[0m\u001b[32m=\u001b[0m\u001b[32mheaders\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n```\\n### 4. \u001b[0m\n",
       "\u001b[32mParse the response\\n\\nThe API will return a JSON object with results. You can parse this response using Python's \u001b[0m\n",
       "\u001b[32mbuilt-in `json` library or another parsing library like `xml.etree.ElementTree`.\\n\\nExample:\\n```python\\nimport \u001b[0m\n",
       "\u001b[32mjson\\n\\nresponse_json = json.loads\u001b[0m\u001b[32m(\u001b[0m\u001b[32mresponse.text\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nprint\u001b[0m\u001b[32m(\u001b[0m\u001b[32mresponse_json\u001b[0m\u001b[32m[\u001b[0m\u001b[32m'object'\u001b[0m\u001b[32m]\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n```\\n### Notes:\\n\\n* The OpenAI \u001b[0m\n",
       "\u001b[32mAPI has usage limits, and the free tier can be used for up to 50 calls per month.\\n* Some features of the API may \u001b[0m\n",
       "\u001b[32mrequire a paid subscription or additional authentication.\\n* Be mindful of OpenAI's terms of service and usage \u001b[0m\n",
       "\u001b[32mguidelines when using their API in production.\"\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1758620686\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'llama3.2'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'text_completion'\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_ollama'\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m677\u001b[0m,\n",
       "        \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m37\u001b[0m,\n",
       "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m714\u001b[0m,\n",
       "        \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "completion = client.completions.create(\n",
    "    model=\"llama3.2\",\n",
    "    prompt=\"What are the instructions to access openAI through a REST API\",\n",
    ")\n",
    "rprint(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">SyncPage<span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">](</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">data</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'mistral:latest'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1757920947</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'library'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'qwen3:8b'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1754128254</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'library'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'llama3.1:latest'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1753760098</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'library'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gemma3:latest'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1750221369</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'library'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'llama3.2:latest'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1742291180</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'library'</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'list'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "SyncPage\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mdata\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'mistral:latest'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1757920947\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'library'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'qwen3:8b'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1754128254\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'library'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'llama3.1:latest'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1753760098\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'library'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gemma3:latest'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1750221369\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'library'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'llama3.2:latest'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1742291180\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'library'\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'list'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "list_completion = client.models.list()\n",
    "rprint(list_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'llama3.2'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1742291180</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">owned_by</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'library'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'llama3.2'\u001b[0m, \u001b[33mcreated\u001b[0m=\u001b[1;36m1742291180\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'model'\u001b[0m, \u001b[33mowned_by\u001b[0m=\u001b[32m'library'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = client.models.retrieve(\"llama3.2\")\n",
    "rprint(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing the same now with OpenAi gpt-4o-mini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not we are not passing any api key here - it is picked automatically from the environment variable `OPENAI_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_openai = OpenAI(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CJBJI9CGAhfcyliWgdLCBmoXcg3Bv'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"To access OpenAI's services through a REST API, you'll typically follow these general </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">steps. Make sure to refer to the official OpenAI API documentation for the most updated details, but heres a basic</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rundown:\\n\\n### Step 1: Get API Key\\n1. **Create an OpenAI Account**: If you haven't already, sign up at [OpenAI's </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">website](https://www.openai.com).\\n2. **Access API Keys**: Once logged in, navigate to the API section of your </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">account to generate a new API key. Keep this key secure as it will be used to authenticate your requests.\\n\\n### </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Step 2: Set Up Your Environment\\n1. **Choose a Programming Language**: Common languages include Python, JavaScript,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">etc.\\n2. **Install Required Libraries**: For example, in Python, you might want to install `requests`.\\n\\n    </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">```bash\\n    pip install requests\\n    ```\\n\\n### Step 3: Make Your First API Call\\nHeres a basic example of how </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to make a request to the OpenAI API.\\n\\n#### Example in Python\\n\\n```python\\nimport requests\\n\\n# Set your API key </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">here\\napi_key = 'your_api_key_here'\\n\\n# Set up the headers\\nheaders = {\\n    'Authorization': f'Bearer </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{api_key}',\\n    'Content-Type': 'application/json'\\n}\\n\\n# Prepare the data for the request\\ndata = {\\n    </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'model': 'text-davinci-003',  # Choose the model you want to use\\n    'prompt': 'Once upon a time...',\\n    </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'max_tokens': 50\\n}\\n\\n# Make the API call\\nresponse = </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">requests.post('https://api.openai.com/v1/engines/text-davinci-003/completions', headers=headers, json=data)\\n\\n# </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Print the response from the API\\nprint(response.json())\\n```\\n\\n### Step 4: Understand the Endpoint\\nDepending on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the task, you may need to use different endpoints. The example above uses the completions endpoint for generating </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">text. Here are some common endpoints:\\n\\n- **Completions**: `/v1/engines/{engine_id}/completions` for text </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">generation.\\n- **Chat Completions**: `/v1/chat/completions` for chat models like gpt-3.5-turbo and gpt-4.\\n- </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">**Fine-tuning**: `/v1/fine-tunes` for custom model training.\\n\\n### Step 5: Error Handling &amp; Response Parsing\\nMake</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sure you handle errors gracefully: check for response status codes, and parse JSON outputs correctly.\\n\\n### Step </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">6: Follow Usage Guidelines\\nBe aware of the usage limits and guidelines outlined by OpenAI to prevent abuse of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">API.\\n\\n### Additional Resources\\n- **Official API Documentation**: Always refer to OpenAI's official docs for the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">latest updates and detailed endpoint information: [OpenAI API </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Documentation](https://platform.openai.com/docs/api-reference).\\n\\n### Important Notes:\\n- Be cautious with your </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">API key; do not expose it in public code repositories or client-side code.\\n- Monitor your usage to avoid </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">unexpected charges if you're on a paid plan.\\n\\nFollowing these steps will help you successfully access the OpenAI </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">API through REST.\"</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1758687744</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_560af6e559'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">651</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">670</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionTokensDetails</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">accepted_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">reasoning_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">rejected_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">cached_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CJBJI9CGAhfcyliWgdLCBmoXcg3Bv'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m\"To\u001b[0m\u001b[32m access OpenAI's services through a REST API, you'll typically follow these general \u001b[0m\n",
       "\u001b[32msteps. Make sure to refer to the official OpenAI API documentation for the most updated details, but heres a basic\u001b[0m\n",
       "\u001b[32mrundown:\\n\\n### Step 1: Get API Key\\n1. **Create an OpenAI Account**: If you haven't already, sign up at \u001b[0m\u001b[32m[\u001b[0m\u001b[32mOpenAI's \u001b[0m\n",
       "\u001b[32mwebsite\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://www.openai.com\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n2. **Access API Keys**: Once logged in, navigate to the API section of your \u001b[0m\n",
       "\u001b[32maccount to generate a new API key. Keep this key secure as it will be used to authenticate your requests.\\n\\n### \u001b[0m\n",
       "\u001b[32mStep 2: Set Up Your Environment\\n1. **Choose a Programming Language**: Common languages include Python, JavaScript,\u001b[0m\n",
       "\u001b[32metc.\\n2. **Install Required Libraries**: For example, in Python, you might want to install `requests`.\\n\\n    \u001b[0m\n",
       "\u001b[32m```bash\\n    pip install requests\\n    ```\\n\\n### Step 3: Make Your First API Call\\nHeres a basic example of how \u001b[0m\n",
       "\u001b[32mto make a request to the OpenAI API.\\n\\n#### Example in Python\\n\\n```python\\nimport requests\\n\\n# Set your API key \u001b[0m\n",
       "\u001b[32mhere\\napi_key = 'your_api_key_here'\\n\\n# Set up the headers\\nheaders = \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    'Authorization': f'Bearer \u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32mapi_key\u001b[0m\u001b[32m}\u001b[0m\u001b[32m',\\n    'Content-Type': 'application/json'\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n# Prepare the data for the request\\ndata = \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \u001b[0m\n",
       "\u001b[32m'model': 'text-davinci-003',  # Choose the model you want to use\\n    'prompt': 'Once upon a time...',\\n    \u001b[0m\n",
       "\u001b[32m'max_tokens': 50\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n# Make the API call\\nresponse = \u001b[0m\n",
       "\u001b[32mrequests.post\u001b[0m\u001b[32m(\u001b[0m\u001b[32m'https://api.openai.com/v1/engines/text-davinci-003/completions', \u001b[0m\u001b[32mheaders\u001b[0m\u001b[32m=\u001b[0m\u001b[32mheaders\u001b[0m\u001b[32m, \u001b[0m\u001b[32mjson\u001b[0m\u001b[32m=\u001b[0m\u001b[32mdata\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n# \u001b[0m\n",
       "\u001b[32mPrint the response from the API\\nprint\u001b[0m\u001b[32m(\u001b[0m\u001b[32mresponse.json\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n```\\n\\n### Step 4: Understand the Endpoint\\nDepending on \u001b[0m\n",
       "\u001b[32mthe task, you may need to use different endpoints. The example above uses the completions endpoint for generating \u001b[0m\n",
       "\u001b[32mtext. Here are some common endpoints:\\n\\n- **Completions**: `/v1/engines/\u001b[0m\u001b[32m{\u001b[0m\u001b[32mengine_id\u001b[0m\u001b[32m}\u001b[0m\u001b[32m/completions` for text \u001b[0m\n",
       "\u001b[32mgeneration.\\n- **Chat Completions**: `/v1/chat/completions` for chat models like gpt-3.5-turbo and gpt-4.\\n- \u001b[0m\n",
       "\u001b[32m**Fine-tuning**: `/v1/fine-tunes` for custom model training.\\n\\n### Step 5: Error Handling & Response Parsing\\nMake\u001b[0m\n",
       "\u001b[32msure you handle errors gracefully: check for response status codes, and parse JSON outputs correctly.\\n\\n### Step \u001b[0m\n",
       "\u001b[32m6: Follow Usage Guidelines\\nBe aware of the usage limits and guidelines outlined by OpenAI to prevent abuse of the \u001b[0m\n",
       "\u001b[32mAPI.\\n\\n### Additional Resources\\n- **Official API Documentation**: Always refer to OpenAI's official docs for the \u001b[0m\n",
       "\u001b[32mlatest updates and detailed endpoint information: \u001b[0m\u001b[32m[\u001b[0m\u001b[32mOpenAI API \u001b[0m\n",
       "\u001b[32mDocumentation\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://platform.openai.com/docs/api-reference\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\\n### Important Notes:\\n- Be cautious with your \u001b[0m\n",
       "\u001b[32mAPI key; do not expose it in public code repositories or client-side code.\\n- Monitor your usage to avoid \u001b[0m\n",
       "\u001b[32munexpected charges if you're on a paid plan.\\n\\nFollowing these steps will help you successfully access the OpenAI \u001b[0m\n",
       "\u001b[32mAPI through REST.\"\u001b[0m,\n",
       "                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33mannotations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1758687744\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[32m'default'\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_560af6e559'\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m651\u001b[0m,\n",
       "        \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m19\u001b[0m,\n",
       "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m670\u001b[0m,\n",
       "        \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[1;35mCompletionTokensDetails\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33maccepted_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mreasoning_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mrejected_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mprompt_tokens_details\u001b[0m=\u001b[1;35mPromptTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mcached_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "chat_completion = client_openai.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'What are the instructions to access openAI through a REST API',\n",
    "        }\n",
    "    ],\n",
    "    model='gpt-4o-mini',\n",
    ")\n",
    "rprint(chat_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Completion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cmpl-CItsO72Gd4eS04m0RHtOklrmN8XcT'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionChoice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'length'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'?**\\n   - To access OpenAI through a REST API, you generally need'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1758620728</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_560af6e559'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionTokensDetails</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">accepted_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">reasoning_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">rejected_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">cached_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'cmpl-CItsO72Gd4eS04m0RHtOklrmN8XcT'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mCompletionChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'length'\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtext\u001b[0m=\u001b[32m'?**\\n   - To access OpenAI through a REST API, you generally need'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1758620728\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'completion'\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_560af6e559'\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
       "        \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m12\u001b[0m,\n",
       "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m28\u001b[0m,\n",
       "        \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[1;35mCompletionTokensDetails\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33maccepted_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mreasoning_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mrejected_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mprompt_tokens_details\u001b[0m=\u001b[1;35mPromptTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mcached_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "completion = client_openai.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    prompt=\"What are the instructions to access openAI through a REST API\",\n",
    ")\n",
    "rprint(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few LLM Sampling Parameters\n",
    "\n",
    "#### Temperature:\n",
    "\n",
    "##### Definition: Controls the randomness of the token sampling process.\n",
    "##### Effect:\n",
    "Lower values (e.g., 0.2) make the output more deterministic, favoring tokens with higher probabilities.\n",
    "Higher values (e.g., 1.0 or 1.5) introduce randomness, which can result in more creative or diverse outputs.\n",
    "##### Use Cases:\n",
    "Use lower values for tasks requiring precision (e.g., code generation or factual answers).\n",
    "Use higher values for creative writing or brainstorming.\n",
    "\n",
    "#### Top-p (Nucleus Sampling):\n",
    "\n",
    "##### Definition: Limits token sampling to a subset of tokens whose cumulative probability is less than a specified threshold.\n",
    "##### Effect:\n",
    "A value of 0.9 means only tokens within the top 90% cumulative probability are considered, reducing low-probability noise.\n",
    "##### Use Cases:\n",
    "Ensures the output is coherent while allowing for some variability.\n",
    "\n",
    "#### Top-k Sampling:\n",
    "\n",
    "##### Definition: Limits token sampling to the top k most probable tokens.\n",
    "##### Effect:\n",
    "Restricts randomness to a fixed number of high-probability options, regardless of cumulative probabilities.\n",
    "##### Use Cases:\n",
    "Works well for tasks requiring diversity while avoiding unlikely tokens.\n",
    "\n",
    "#### Frequency Penalty:\n",
    "\n",
    "##### Definition: Penalizes tokens that have already appeared in the generated text.\n",
    "##### Effect:\n",
    "Reduces repetition by lowering the likelihood of previously used words.\n",
    "##### Use Cases:\n",
    "Ideal for generating long-form content like essays or stories.\n",
    "\n",
    "#### Presence Penalty:\n",
    "\n",
    "##### Definition: Penalizes tokens based on their presence in the text so far.\n",
    "##### Effect:\n",
    "Encourages introducing new topics or ideas into the output.\n",
    "##### Use Cases:\n",
    "Useful for exploratory or brainstorming tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**See below how the output varies for the same prompt with different values for temperature and nucleus sampling (top_p)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "\n",
    "    # required but ignored\n",
    "    api_key='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Angelo was a bright-eyed and curious nine-year-old boy who lived in the small village of Azura, nestled in the \n",
       "rolling hills of Tuscany. His home was a small stone cottage with a thatched roof, surrounded by fields of golden \n",
       "wheat and sunflowers that seemed to stretch up to the sky.\n",
       "\n",
       "Every morning, Angelo would wake up early, before the sun had fully risen, and venture out into the village \n",
       "streets. He loved watching the villagers stir to life as they began their daily routines  tending to their \n",
       "gardens, fixing tools, or simply enjoying a warm cup of coffee on the piazza.\n",
       "\n",
       "Angelo's mother, Maria, was a skilled weaver who spent her days creating beautiful tapestries and blankets from the\n",
       "soft wool of the village sheep. She had passed down her knowledge of weaving to Angelo, and he loved to sit by her \n",
       "side as she worked, learning the intricacies of thread and yarn.\n",
       "\n",
       "One day, while exploring the surrounding countryside, Angelo stumbled upon a small clearing surrounded by tall \n",
       "trees. In the center of the clearing stood an ancient oak tree, its branches twisted and gnarled with age. As \n",
       "Angelo approached the tree, he noticed that it was covered in strange symbols  intricate carvings etched into the \n",
       "bark.\n",
       "\n",
       "Angelo's curiosity got the better of him, and he reached out to touch one of the symbols. To his surprise, the \n",
       "symbol began to glow with a soft, golden light. Suddenly, the air around him was filled with a sweet, musical hum \n",
       "that seemed to come from nowhere and everywhere at the same time.\n",
       "\n",
       "As the hum grew louder, Angelo felt himself being drawn into the tree's ancient power. He closed his eyes, letting \n",
       "the energy wash over him, and when he opened them again, he found himself standing in a lush meadow filled with \n",
       "wildflowers  sunflowers that shimmered like gold in the sunlight.\n",
       "\n",
       "A figure appeared before him, cloaked in shadows. It was an old woman, her face lined with age and wisdom. She \n",
       "spoke in a soft, melodious voice, saying, <span style=\"color: #008000; text-decoration-color: #008000\">\"Angelo, you have been chosen to be a guardian of this land. Your </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">curiosity and kindness will serve you well on your journey.\"</span>\n",
       "\n",
       "With those words, the old woman vanished into thin air, leaving Angelo alone in the meadow. He wandered the fields,\n",
       "taking in the beauty around him, feeling a sense of wonder and awe that he had never experienced before.\n",
       "\n",
       "When he returned to village life, his eyes were opened to new possibilities. He began to notice the intricate web \n",
       "of relationships between the villagers, the whispers of ancient stories carried on the wind, and the secrets hidden\n",
       "in plain sight. Angelo knew that he had been given a special gift  the ability to see the world in a way few \n",
       "others did.\n",
       "\n",
       "From that day forward, Angelo dedicated himself to learning about his land, its history, and its magic. His mother \n",
       "watched with pride as her son grew into a confident, thoughtful young man, one who was kinder to the earth and its \n",
       "creatures.\n",
       "\n",
       "As the sun set over Azura village, casting shadows across the fields, Angelo sat by his mother's side in their cozy\n",
       "cottage, weaving tales of wonder into the fabric of their lives. The stories of that ancient oak tree, and the \n",
       "world that had unfolded before him like a mysterious tapestry, would forever be woven into the thread of family \n",
       "tradition  passed down from one generation to the next, a testament to the magic that lay just beyond every corner\n",
       "of their small but vibrant village life.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Angelo was a bright-eyed and curious nine-year-old boy who lived in the small village of Azura, nestled in the \n",
       "rolling hills of Tuscany. His home was a small stone cottage with a thatched roof, surrounded by fields of golden \n",
       "wheat and sunflowers that seemed to stretch up to the sky.\n",
       "\n",
       "Every morning, Angelo would wake up early, before the sun had fully risen, and venture out into the village \n",
       "streets. He loved watching the villagers stir to life as they began their daily routines  tending to their \n",
       "gardens, fixing tools, or simply enjoying a warm cup of coffee on the piazza.\n",
       "\n",
       "Angelo's mother, Maria, was a skilled weaver who spent her days creating beautiful tapestries and blankets from the\n",
       "soft wool of the village sheep. She had passed down her knowledge of weaving to Angelo, and he loved to sit by her \n",
       "side as she worked, learning the intricacies of thread and yarn.\n",
       "\n",
       "One day, while exploring the surrounding countryside, Angelo stumbled upon a small clearing surrounded by tall \n",
       "trees. In the center of the clearing stood an ancient oak tree, its branches twisted and gnarled with age. As \n",
       "Angelo approached the tree, he noticed that it was covered in strange symbols  intricate carvings etched into the \n",
       "bark.\n",
       "\n",
       "Angelo's curiosity got the better of him, and he reached out to touch one of the symbols. To his surprise, the \n",
       "symbol began to glow with a soft, golden light. Suddenly, the air around him was filled with a sweet, musical hum \n",
       "that seemed to come from nowhere and everywhere at the same time.\n",
       "\n",
       "As the hum grew louder, Angelo felt himself being drawn into the tree's ancient power. He closed his eyes, letting \n",
       "the energy wash over him, and when he opened them again, he found himself standing in a lush meadow filled with \n",
       "wildflowers  sunflowers that shimmered like gold in the sunlight.\n",
       "\n",
       "A figure appeared before him, cloaked in shadows. It was an old woman, her face lined with age and wisdom. She \n",
       "spoke in a soft, melodious voice, saying, \u001b[32m\"Angelo, you have been chosen to be a guardian of this land. Your \u001b[0m\n",
       "\u001b[32mcuriosity and kindness will serve you well on your journey.\"\u001b[0m\n",
       "\n",
       "With those words, the old woman vanished into thin air, leaving Angelo alone in the meadow. He wandered the fields,\n",
       "taking in the beauty around him, feeling a sense of wonder and awe that he had never experienced before.\n",
       "\n",
       "When he returned to village life, his eyes were opened to new possibilities. He began to notice the intricate web \n",
       "of relationships between the villagers, the whispers of ancient stories carried on the wind, and the secrets hidden\n",
       "in plain sight. Angelo knew that he had been given a special gift  the ability to see the world in a way few \n",
       "others did.\n",
       "\n",
       "From that day forward, Angelo dedicated himself to learning about his land, its history, and its magic. His mother \n",
       "watched with pride as her son grew into a confident, thoughtful young man, one who was kinder to the earth and its \n",
       "creatures.\n",
       "\n",
       "As the sun set over Azura village, casting shadows across the fields, Angelo sat by his mother's side in their cozy\n",
       "cottage, weaving tales of wonder into the fabric of their lives. The stories of that ancient oak tree, and the \n",
       "world that had unfolded before him like a mysterious tapestry, would forever be woven into the thread of family \n",
       "tradition  passed down from one generation to the next, a testament to the magic that lay just beyond every corner\n",
       "of their small but vibrant village life.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "completion = client.completions.create(\n",
    "    model=\"llama3.2\",\n",
    "    prompt=\"Write a story about a young boy named Angelo from a small village\",\n",
    "    #temperature=3.0,\n",
    "    #top_p=0.7,\n",
    "    n=1,\n",
    ")\n",
    "rprint(completion.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing temperature increases uncertainty (increases \"creativity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Angleleo lived inside some amazing ancient walls nestled amongst towering volcanes; this place looked pretty good \n",
       "without looking quite magical due though since I had not. A year of ages is very hard however as every waking \n",
       "single day can see all one's true self become visible, it should always say for every dream there needs something \n",
       "different at heart as in every child but in this case he had done this more for fun than an evil cause in other \n",
       "children at around Angelo he played games or read under. Sun to learn things you cannot, some were from when one \n",
       "had left everything so that could just do like before so his life inside of the little room where things went down \n",
       "he liked most and had his dream of building bridges but even this was all pretty easy now as only what people \n",
       "looked and could be it still wasnt in time enough because of a little bird he lived so happy inside in village and\n",
       "was content as this meant every need met by mother.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Angleleo lived inside some amazing ancient walls nestled amongst towering volcanes; this place looked pretty good \n",
       "without looking quite magical due though since I had not. A year of ages is very hard however as every waking \n",
       "single day can see all one's true self become visible, it should always say for every dream there needs something \n",
       "different at heart as in every child but in this case he had done this more for fun than an evil cause in other \n",
       "children at around Angelo he played games or read under. Sun to learn things you cannot, some were from when one \n",
       "had left everything so that could just do like before so his life inside of the little room where things went down \n",
       "he liked most and had his dream of building bridges but even this was all pretty easy now as only what people \n",
       "looked and could be it still wasnt in time enough because of a little bird he lived so happy inside in village and\n",
       "was content as this meant every need met by mother.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "completion = client.completions.create(\n",
    "    model=\"llama3.2\",\n",
    "    prompt=\"Write a story about a young boy named Angelo from a small village\",\n",
    "    temperature=3.0,\n",
    "    #top_p=0.7,\n",
    "    n=1,\n",
    ")\n",
    "rprint(completion.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decreasing top_p (as well as temperature) has the opposite effect (makes response less uncertain). Typically we vary only one of these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">In the heart of a small, sun-kissed village nestled between two great hills, there lived a young boy named Angelo. \n",
       "The villagers knew him as the bright-eyed and curious son of a humble farmer, Giovanni. Angelo's days were filled \n",
       "with the simple joys of childhood: playing in the fields, chasing after the family's chickens, and helping his \n",
       "father with the daily chores.\n",
       "\n",
       "Angelo's village was a tight-knit community where everyone knew each other's names and stories. The villagers would\n",
       "often gather at the town square to share news, gossip, and laughter. Angelo loved listening to their tales of \n",
       "adventure and bravery, which only fueled his own imagination and sense of wonder.\n",
       "\n",
       "One day, while wandering through the fields, Angelo stumbled upon a hidden path he had never seen before. The path \n",
       "was overgrown with weeds and vines, but something about it drew him in. He felt an inexplicable urge to explore it \n",
       "further, and so, with a thrill of excitement, he set off on his adventure.\n",
       "\n",
       "As he walked along the winding path, Angelo noticed that it led him deeper into the hills, where the air grew thick\n",
       "with the scent of wildflowers and herbs. The sun beat down upon him, casting dappled shadows across the ground. \n",
       "With each step, the path grew narrower and more treacherous, but Angelo's curiosity kept him going.\n",
       "\n",
       "Suddenly, he heard a faint rustling in the bushes ahead. Angelo froze, his heart pounding with excitement. What \n",
       "could be hiding in the underbrush? He took another cautious step forward, and to his surprise, a magnificent eagle \n",
       "emerged from the shadows.\n",
       "\n",
       "The eagle's feathers glistened in the sunlight, and its piercing gaze seemed to see right through Angelo. For a \n",
       "moment, they locked eyes, and then, with a soft flutter of wings, the eagle took flight. Angelo watched in awe as \n",
       "it soared above him, its shadow dancing across the ground below.\n",
       "\n",
       "As he continued on his journey, Angelo discovered that the hidden path led him to a secret glade deep within the \n",
       "hills. The air was filled with the sweet scent of wildflowers, and the sound of gentle music drifted through the \n",
       "trees. In the center of the clearing stood an ancient tree, its branches twisted and gnarled with age.\n",
       "\n",
       "Angelo approached the tree cautiously, feeling as though he had stumbled upon a hidden treasure. As he reached out \n",
       "to touch the trunk, the tree began to whisper secrets in his ear. The wind carried the whispers on its breath, \n",
       "telling tales of old: stories of love, loss, and adventure that echoed through the hills for generations.\n",
       "\n",
       "Enchanted by the ancient tree's wisdom, Angelo spent hours listening to its tales. As the sun began to set, casting\n",
       "a warm orange glow over the glade, he reluctantly bid farewell to his new friend. The eagle reappeared, flying \n",
       "above him once more as a symbol of their special bond.\n",
       "\n",
       "From that day on, Angelo returned to the hidden path and the ancient tree whenever he could. He would sit at its \n",
       "base, listening to its whispers and sharing his own stories with the wind. As the years passed, the villagers began\n",
       "to notice changes in Angelo's demeanor: a newfound confidence, a spark of creativity, and an unquenchable thirst \n",
       "for adventure.\n",
       "\n",
       "Angelo had discovered a secret world hidden within the hills, and it had forever changed him. He grew into a brave \n",
       "and wise young man, carrying the wisdom of the ancient tree with him always. And though he never forgot his humble \n",
       "beginnings in the small village, Angelo knew that there was a greater world beyond the horizon, waiting to be \n",
       "explored and cherished.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "In the heart of a small, sun-kissed village nestled between two great hills, there lived a young boy named Angelo. \n",
       "The villagers knew him as the bright-eyed and curious son of a humble farmer, Giovanni. Angelo's days were filled \n",
       "with the simple joys of childhood: playing in the fields, chasing after the family's chickens, and helping his \n",
       "father with the daily chores.\n",
       "\n",
       "Angelo's village was a tight-knit community where everyone knew each other's names and stories. The villagers would\n",
       "often gather at the town square to share news, gossip, and laughter. Angelo loved listening to their tales of \n",
       "adventure and bravery, which only fueled his own imagination and sense of wonder.\n",
       "\n",
       "One day, while wandering through the fields, Angelo stumbled upon a hidden path he had never seen before. The path \n",
       "was overgrown with weeds and vines, but something about it drew him in. He felt an inexplicable urge to explore it \n",
       "further, and so, with a thrill of excitement, he set off on his adventure.\n",
       "\n",
       "As he walked along the winding path, Angelo noticed that it led him deeper into the hills, where the air grew thick\n",
       "with the scent of wildflowers and herbs. The sun beat down upon him, casting dappled shadows across the ground. \n",
       "With each step, the path grew narrower and more treacherous, but Angelo's curiosity kept him going.\n",
       "\n",
       "Suddenly, he heard a faint rustling in the bushes ahead. Angelo froze, his heart pounding with excitement. What \n",
       "could be hiding in the underbrush? He took another cautious step forward, and to his surprise, a magnificent eagle \n",
       "emerged from the shadows.\n",
       "\n",
       "The eagle's feathers glistened in the sunlight, and its piercing gaze seemed to see right through Angelo. For a \n",
       "moment, they locked eyes, and then, with a soft flutter of wings, the eagle took flight. Angelo watched in awe as \n",
       "it soared above him, its shadow dancing across the ground below.\n",
       "\n",
       "As he continued on his journey, Angelo discovered that the hidden path led him to a secret glade deep within the \n",
       "hills. The air was filled with the sweet scent of wildflowers, and the sound of gentle music drifted through the \n",
       "trees. In the center of the clearing stood an ancient tree, its branches twisted and gnarled with age.\n",
       "\n",
       "Angelo approached the tree cautiously, feeling as though he had stumbled upon a hidden treasure. As he reached out \n",
       "to touch the trunk, the tree began to whisper secrets in his ear. The wind carried the whispers on its breath, \n",
       "telling tales of old: stories of love, loss, and adventure that echoed through the hills for generations.\n",
       "\n",
       "Enchanted by the ancient tree's wisdom, Angelo spent hours listening to its tales. As the sun began to set, casting\n",
       "a warm orange glow over the glade, he reluctantly bid farewell to his new friend. The eagle reappeared, flying \n",
       "above him once more as a symbol of their special bond.\n",
       "\n",
       "From that day on, Angelo returned to the hidden path and the ancient tree whenever he could. He would sit at its \n",
       "base, listening to its whispers and sharing his own stories with the wind. As the years passed, the villagers began\n",
       "to notice changes in Angelo's demeanor: a newfound confidence, a spark of creativity, and an unquenchable thirst \n",
       "for adventure.\n",
       "\n",
       "Angelo had discovered a secret world hidden within the hills, and it had forever changed him. He grew into a brave \n",
       "and wise young man, carrying the wisdom of the ancient tree with him always. And though he never forgot his humble \n",
       "beginnings in the small village, Angelo knew that there was a greater world beyond the horizon, waiting to be \n",
       "explored and cherished.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "completion = client.completions.create(\n",
    "    model=\"llama3.2\",\n",
    "    prompt=\"Write a story about a young boy named Angelo from a small village\",\n",
    "    #temperature=3.0,\n",
    "    top_p=0.7,\n",
    "    n=1,\n",
    ")\n",
    "rprint(completion.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that the above OpenAI calls allow for playing with the various parameters - temperature, top_p, frequency_penalty, presence_penalty,  but there is no explicit support for top_k**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
